# QueryEngine - Query Processing Engine

QueryEngine orchestrates the complete query-to-answer workflow with automatic normalization based on corpus state and flexible component configuration.

## Overview

QueryEngine provides intelligent query processing with the following workflow:

1. **Query Normalization** - Automatic normalization based on corpus state
2. **Document Retrieval** - Multi-retriever support with flexible configuration
3. **Result Reranking** - Optional reranking for relevance optimization
4. **Answer Generation** - Context-aware answer synthesis

```python
from refinire_rag.application import QueryEngine, QueryEngineConfig
from refinire_rag.retrieval import SimpleRetriever, SimpleReranker, AnswerSynthesizer

# Create components
retriever = SimpleRetriever(vector_store, embedder)
reranker = SimpleReranker()
synthesizer = AnswerSynthesizer()

# Create QueryEngine
query_engine = QueryEngine(
    corpus_name="knowledge_base",
    retrievers=retriever,  # Can be single retriever or list
    synthesizer=synthesizer,
    reranker=reranker,  # Optional
    config=QueryEngineConfig()
)
```

## Public API Methods

### __init__

Initialize QueryEngine with components and configuration.

```python
QueryEngine(
    corpus_name: str,
    retrievers: Union[Retriever, List[Retriever]],
    synthesizer: AnswerSynthesizer,
    reranker: Optional[Reranker] = None,
    config: Optional[QueryEngineConfig] = None
)
```

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `corpus_name` | `str` | Required | Name of the corpus for this query engine |
| `retrievers` | `Union[Retriever, List[Retriever]]` | Required | Single retriever or list of retrievers |
| `synthesizer` | `AnswerSynthesizer` | Required | Component for answer generation |
| `reranker` | `Optional[Reranker]` | `None` | Optional component for result reranking |
| `config` | `Optional[QueryEngineConfig]` | `None` | Configuration for the engine |

### set_normalizer

Set normalizer for query processing.

```python
set_normalizer(normalizer: Optional[Normalizer]) -> None
```

### query

Generate answer for user query.

```python
query(query: str, context: Optional[Dict[str, Any]] = None) -> QueryResult
```

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `query` | `str` | Required | User query string |
| `context` | `Optional[Dict[str, Any]]` | `None` | Optional context parameters (top_k, filters, etc.) |

### add_retriever

Add a new retriever to the engine.

```python
add_retriever(retriever: Retriever) -> None
```

### remove_retriever

Remove a retriever by index.

```python
remove_retriever(index: int) -> bool
```

### get_engine_stats

Get comprehensive engine statistics.

```python
get_engine_stats() -> Dict[str, Any]
```

### clear_cache

Clear any cached data.

```python
clear_cache() -> None
```

## QueryEngineConfig

Configuration class that controls QueryEngine behavior.

```python
@dataclass
class QueryEngineConfig:
    # Query processing settings
    enable_query_normalization: bool = True
    
    # Component settings
    retriever_top_k: int = 10                    # Results per retriever
    total_top_k: int = 20                        # Total results after combining
    reranker_top_k: int = 5                      # Final results after reranking
    synthesizer_max_context: int = 2000          # Max context for answer generation
    
    # Performance settings
    enable_caching: bool = True
    cache_ttl: int = 3600                        # Cache TTL in seconds
    
    # Output settings
    include_sources: bool = True
    include_confidence: bool = True
    include_processing_metadata: bool = True
    
    # Multi-retriever settings
    deduplicate_results: bool = True             # Remove duplicate documents
    combine_scores: str = "max"                  # How to combine scores
```

## Usage Examples

### Basic Query Processing

```python
from refinire_rag.application import QueryEngine
from refinire_rag.retrieval import SimpleRetriever, AnswerSynthesizer

# Setup components
retriever = SimpleRetriever(vector_store, embedder)
synthesizer = AnswerSynthesizer()

# Create QueryEngine
query_engine = QueryEngine(
    corpus_name="knowledge_base",
    retrievers=retriever,
    synthesizer=synthesizer
)

# Process query
result = query_engine.query("How does RAG work?")
print(f"Answer: {result.answer}")
print(f"Sources: {len(result.sources)}")
```

### Multi-Retriever Setup

```python
from refinire_rag.retrieval import SimpleRetriever, HybridRetriever

# Multiple retrievers for different search strategies
vector_retriever = SimpleRetriever(vector_store, embedder)
hybrid_retriever = HybridRetriever(vector_store, keyword_store)

query_engine = QueryEngine(
    corpus_name="knowledge_base",
    retrievers=[vector_retriever, hybrid_retriever],  # List of retrievers
    synthesizer=synthesizer,
    config=QueryEngineConfig(
        total_top_k=30,  # More results from multiple retrievers
        reranker_top_k=5
    )
)
```

### Advanced Configuration with Normalization

```python
from refinire_rag.processing import Normalizer

# Configure with normalization
config = QueryEngineConfig(
    enable_query_normalization=True,
    retriever_top_k=15,
    total_top_k=25,
    reranker_top_k=8,
    include_processing_metadata=True,
    deduplicate_results=True,
    combine_scores="average"
)

query_engine = QueryEngine(
    corpus_name="knowledge_base",
    retrievers=[vector_retriever, hybrid_retriever],
    synthesizer=synthesizer,
    reranker=reranker,
    config=config
)

# Set normalizer for query processing
normalizer = Normalizer(dictionary_path="./knowledge_base_dictionary.md")
query_engine.set_normalizer(normalizer)
```

### Query with Context Parameters

```python
# Query with custom context
result = query_engine.query(
    query="How does machine learning work?",
    context={
        "retriever_top_k": 20,  # Override default
        "rerank_top_k": 10,     # Override default
        "filters": {"document_type": "technical"}
    }
)

print(f"Answer: {result.answer}")
print(f"Confidence: {result.confidence}")
print(f"Processing time: {result.processing_time}")
```

## QueryResult Object

The `query` method returns a `QueryResult` object with the following structure:

```python
@dataclass
class QueryResult:
    answer: str                          # Generated answer
    confidence: float                    # Confidence score
    sources: List[SearchResult]          # Source documents
    processing_time: float               # Total processing time
    query_metadata: Dict[str, Any]       # Processing metadata
    
    # Optional fields based on configuration
    normalized_query: Optional[str]      # Normalized query (if enabled)
    retrieval_results: Optional[List]    # Raw retrieval results
    reranking_results: Optional[List]    # Reranked results
```

## Engine Statistics

```python
# Get comprehensive engine statistics
stats = query_engine.get_engine_stats()

print(f"Total queries processed: {stats['total_queries']}")
print(f"Average processing time: {stats['avg_processing_time']:.2f}s")
print(f"Cache hit rate: {stats['cache_hit_rate']:.1%}")
print(f"Number of retrievers: {stats['num_retrievers']}")
```

## Best Practices

1. **Multi-Retriever Strategy**: Use multiple retrievers for comprehensive coverage
2. **Normalization**: Enable query normalization for improved consistency
3. **Caching**: Keep caching enabled for better performance
4. **Context Parameters**: Use context parameters for dynamic query tuning
5. **Statistics Monitoring**: Monitor engine statistics for performance optimization

## Complete Example

```python
from refinire_rag.application import QueryEngine, QueryEngineConfig
from refinire_rag.retrieval import SimpleRetriever, HybridRetriever, AnswerSynthesizer, SimpleReranker
from refinire_rag.processing import Normalizer

def create_query_engine():
    # Initialize components
    vector_retriever = SimpleRetriever(vector_store, embedder)
    hybrid_retriever = HybridRetriever(vector_store, keyword_store)
    reranker = SimpleReranker()
    synthesizer = AnswerSynthesizer()
    
    # Configure engine
    config = QueryEngineConfig(
        enable_query_normalization=True,
        retriever_top_k=15,
        total_top_k=25,
        reranker_top_k=8,
        include_sources=True,
        include_confidence=True,
        deduplicate_results=True
    )
    
    # Create QueryEngine
    query_engine = QueryEngine(
        corpus_name="knowledge_base",
        retrievers=[vector_retriever, hybrid_retriever],
        synthesizer=synthesizer,
        reranker=reranker,
        config=config
    )
    
    # Set up normalization
    normalizer = Normalizer(dictionary_path="./knowledge_base_dictionary.md")
    query_engine.set_normalizer(normalizer)
    
    return query_engine

# Usage
query_engine = create_query_engine()

# Process queries
result = query_engine.query("What are the benefits of RAG?")
print(f"Answer: {result.answer}")
print(f"Confidence: {result.confidence:.2f}")
print(f"Sources used: {len(result.sources)}")

# Get statistics
stats = query_engine.get_engine_stats()
print(f"Total queries: {stats['total_queries']}")
```
    confidence: float             # Answer confidence (0.0-1.0)
    metadata: Dict[str, Any]      # Metadata
    processing_time: float        # Processing time (seconds)
    normalized_query: str         # Normalized query
```

### Using Results

```python
result = query_engine.answer("What are the advantages of RAG?")

# Basic information
print(f"Question: {result.query}")
print(f"Answer: {result.answer}")
print(f"Confidence: {result.confidence:.2%}")

# Source information
print("\nReferenced sources:")
for i, source in enumerate(result.sources[:3], 1):
    print(f"{i}. {source.metadata.get('title', 'Unknown')}")
    print(f"   Score: {source.score:.3f}")
    print(f"   Content: {source.content[:100]}...")

# Metadata
if result.metadata.get('query_normalized'):
    print(f"\nQuery normalized: {result.normalized_query}")
print(f"Processing time: {result.processing_time:.3f} seconds")
```

## Component Customization

### Custom Retriever

```python
from refinire_rag.retrieval.base import Retriever

class CustomRetriever(Retriever):
    def retrieve(self, query: str, top_k: int = 10) -> List[SearchResult]:
        # Custom search logic
        pass

# Usage
custom_retriever = CustomRetriever()
query_engine = QueryEngine(
    document_store=doc_store,
    vector_store=vector_store,
    retriever=custom_retriever,
    reader=reader
)
```

### Custom Reader

```python
from refinire_rag.retrieval.base import Reader

class CustomReader(Reader):
    def generate_answer(
        self, 
        query: str, 
        contexts: List[str]
    ) -> str:
        # Custom answer generation logic
        pass
```

## Error Handling

```python
try:
    result = query_engine.answer(query)
except TimeoutError:
    print("Query processing timed out")
except RetrievalError as e:
    print(f"Retrieval error: {e}")
except GenerationError as e:
    print(f"Generation error: {e}")
```

## Performance Optimization

### Caching

```python
# QueryEngine with cache
query_engine = QueryEngine(
    document_store=doc_store,
    vector_store=vector_store,
    retriever=retriever,
    reader=reader,
    cache_enabled=True,
    cache_ttl=3600  # 1 hour
)
```

### Batch Processing

```python
# Batch processing multiple queries
queries = ["Question 1", "Question 2", "Question 3"]
results = query_engine.batch_answer(queries)
```

## Best Practices

1. **Appropriate top_k settings**: Balance between accuracy and performance
2. **Utilize normalization**: Especially effective for Japanese queries
3. **Timeout settings**: Prevent long processing times
4. **Error handling**: Improve user experience

```python
# Recommended settings example
config = QueryEngineConfig(
    enable_query_normalization=True,
    retriever_top_k=15,    # Get sufficient candidates
    reranker_top_k=3,      # Finally narrow down to 3
    include_sources=True,   # For debugging and reliability
    query_timeout=10.0      # 10 second timeout
)
```