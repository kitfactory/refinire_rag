#!/usr/bin/env python3
"""
ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«1: åŸºæœ¬çš„ãªRAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

ã“ã®ã‚µãƒ³ãƒ—ãƒ«ã§ã¯ã€refinire-ragã‚’ä½¿ç”¨ã—ã¦æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªRAGã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã€
åŸºæœ¬çš„ãªè³ªç–‘å¿œç­”æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from refinire_rag.application.corpus_manager_new import CorpusManager
from refinire_rag.application.query_engine import QueryEngine
from refinire_rag.storage.sqlite_store import SQLiteDocumentStore
from refinire_rag.storage.in_memory_vector_store import InMemoryVectorStore
from refinire_rag.retrieval import SimpleRetriever, SimpleReranker, SimpleReader
from refinire_rag.embedding import TFIDFEmbedder, TFIDFEmbeddingConfig
from refinire_rag.models.document import Document
from refinire_rag.storage.vector_store import VectorEntry


def create_sample_documents():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ"""
    
    documents = [
        Document(
            id="doc1",
            content="""
            RAGï¼ˆRetrieval-Augmented Generationï¼‰ã¯ã€æ¤œç´¢æ‹¡å¼µç”ŸæˆæŠ€è¡“ã§ã™ã€‚
            å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã¨å¤–éƒ¨çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’çµ„ã¿åˆã‚ã›ã€
            ã‚ˆã‚Šæ­£ç¢ºã§æ ¹æ‹ ã®ã‚ã‚‹å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
            ä¸»ãªåˆ©ç‚¹ã¯ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®æ¸›å°‘ã€çŸ¥è­˜ã®æ›´æ–°å®¹æ˜“æ€§ã€
            å°‚é–€ãƒ‰ãƒ¡ã‚¤ãƒ³ã¸ã®é©å¿œæ€§ã§ã™ã€‚
            """,
            metadata={"title": "RAGæ¦‚è¦", "category": "æŠ€è¡“"}
        ),
        
        Document(
            id="doc2",
            content="""
            ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¯ã€æ„å‘³çš„é¡ä¼¼æ€§ã«åŸºã¥ãæ¤œç´¢æŠ€è¡“ã§ã™ã€‚
            æ–‡æ›¸ã‚„ã‚¯ã‚¨ãƒªã‚’é«˜æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã«åŸ‹ã‚è¾¼ã¿ã€
            ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãªã©ã‚’ä½¿ç”¨ã—ã¦é–¢é€£æ€§ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
            å¾“æ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§ã¯ç™ºè¦‹ã§ããªã„
            æ–‡è„ˆçš„ã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
            """,
            metadata={"title": "ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢", "category": "æŠ€è¡“"}
        ),
        
        Document(
            id="doc3",
            content="""
            å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã¯ã€è‡ªç„¶è¨€èªå‡¦ç†ã®ä¸­æ ¸æŠ€è¡“ã§ã™ã€‚
            GPTã€Claudeã€Geminiãªã©ã®å…ˆé€²ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ã€
            æ–‡ç« ç”Ÿæˆã€ç¿»è¨³ã€è¦ç´„ã€è³ªç–‘å¿œç­”ãªã©
            å¹…åºƒã„ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã§ãã¾ã™ã€‚
            ä¼æ¥­ã§ã¯ã€ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆã€
            æ–‡æ›¸è§£æãªã©ã®ç”¨é€”ã§æ´»ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
            """,
            metadata={"title": "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«", "category": "æŠ€è¡“"}
        )
    ]
    
    return documents


def setup_storage():
    """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’åˆæœŸåŒ–"""
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨åŸæ–‡ã‚’ä¿å­˜ï¼‰
    document_store = SQLiteDocumentStore(":memory:")
    
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ï¼ˆåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿å­˜ï¼‰
    vector_store = InMemoryVectorStore()
    
    return document_store, vector_store


def build_simple_corpus(documents, document_store, vector_store):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªã‚³ãƒ¼ãƒ‘ã‚¹ã‚’æ§‹ç¯‰"""
    
    print("ğŸ“š ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ä¸­...")
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ‰‹å‹•ã§ã‚¹ãƒˆã‚¢ã«è¿½åŠ 
    for doc in documents:
        document_store.store_document(doc)
    
    # ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã‚’æ‰‹å‹•ã§ä½œæˆ
    embedder_config = TFIDFEmbeddingConfig(min_df=1, max_df=1.0)
    embedder = TFIDFEmbedder(config=embedder_config)
    
    # ã‚³ãƒ¼ãƒ‘ã‚¹ã§embedderã‚’è¨“ç·´
    corpus_texts = [doc.content for doc in documents]
    embedder.fit(corpus_texts)
    
    # å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¦ã‚¹ãƒˆã‚¢
    for doc in documents:
        embedding_result = embedder.embed_text(doc.content)
        vector_entry = VectorEntry(
            document_id=doc.id,
            content=doc.content[:200] + "..." if len(doc.content) > 200 else doc.content,
            embedding=embedding_result.vector.tolist(),
            metadata=doc.metadata
        )
        vector_store.add_vector(vector_entry)
    
    print(f"âœ… {len(documents)}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸ")
    return embedder


def create_query_engine(document_store, vector_store, embedder):
    """ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆ"""
    
    print("ğŸ¤– ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆä¸­...")
    
    # æ¤œç´¢ãƒ»å›ç­”ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½œæˆ
    retriever = SimpleRetriever(vector_store, embedder=embedder)
    reranker = SimpleReranker()
    reader = SimpleReader()
    
    # ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆ
    query_engine = QueryEngine(
        document_store=document_store,
        vector_store=vector_store,
        retriever=retriever,
        reader=reader,
        reranker=reranker
    )
    
    print("âœ… ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆã—ã¾ã—ãŸ")
    return query_engine


def test_questions(query_engine):
    """è³ªå•ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹"""
    
    questions = [
        "RAGã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ä»•çµ„ã¿ã‚’æ•™ãˆã¦",
        "LLMã®ä¸»ãªç”¨é€”ã¯ï¼Ÿ",
        "RAGã®åˆ©ç‚¹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„"
    ]
    
    print("\n" + "="*60)
    print("ğŸ” è³ªç–‘å¿œç­”ãƒ†ã‚¹ãƒˆ")
    print("="*60)
    
    for i, question in enumerate(questions, 1):
        print(f"\nğŸ“Œ è³ªå• {i}: {question}")
        print("-" * 40)
        
        try:
            result = query_engine.answer(question)
            
            print(f"ğŸ¤– å›ç­”:")
            # æ”¹è¡Œã§åˆ†å‰²ã—ã¦è¦‹ã‚„ã™ãè¡¨ç¤º
            answer_lines = result.answer.split('\n')
            for line in answer_lines:
                if line.strip():
                    print(f"   {line.strip()}")
            
            print(f"\nğŸ“Š è©³ç´°:")
            print(f"   - å‡¦ç†æ™‚é–“: {result.metadata.get('processing_time', 0):.3f}ç§’")
            print(f"   - å‚è€ƒæ–‡æ›¸æ•°: {result.metadata.get('source_count', 0)}")
            print(f"   - ä¿¡é ¼åº¦: {result.confidence:.3f}")
            
            if result.sources:
                print(f"   - ä¸»ãªå‚è€ƒæ–‡æ›¸: {result.sources[0].metadata.get('title', 'Unknown')}")
                
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")


def show_corpus_stats(document_store, vector_store):
    """ã‚³ãƒ¼ãƒ‘ã‚¹ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
    
    print("\n" + "="*60)
    print("ğŸ“Š ã‚³ãƒ¼ãƒ‘ã‚¹çµ±è¨ˆæƒ…å ±")
    print("="*60)
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°
    try:
        # SQLiteDocumentStoreã®å†…éƒ¨å®Ÿè£…ã‚’ä½¿ç”¨ã—ã¦æ–‡æ›¸æ•°ã‚’å–å¾—
        cursor = document_store.connection.cursor()
        cursor.execute("SELECT COUNT(*) FROM documents")
        doc_count = cursor.fetchone()[0]
        print(f"ğŸ“„ ä¿å­˜æ–‡æ›¸æ•°: {doc_count}")
    except:
        print(f"ğŸ“„ ä¿å­˜æ–‡æ›¸æ•°: å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
    
    # ãƒ™ã‚¯ãƒˆãƒ«æ•°
    vector_count = len(vector_store._vectors) if hasattr(vector_store, '_vectors') else 0
    print(f"ğŸ”¢ ãƒ™ã‚¯ãƒˆãƒ«æ•°: {vector_count}")
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«
    if vector_count > 0:
        sample_vector = next(iter(vector_store._vectors.values()))
        print(f"ğŸ“ ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {len(sample_vector.embedding)}")
        print(f"ğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {sample_vector.metadata}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    print("ğŸš€ åŸºæœ¬çš„ãªRAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«")
    print("="*60)
    print("ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€refinire-ragã‚’ä½¿ç”¨ã—ã¦")
    print("æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªRAGã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã€è³ªç–‘å¿œç­”æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚")
    
    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1: ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ
        print("\nğŸ“ ã‚¹ãƒ†ãƒƒãƒ—1: ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ")
        documents = create_sample_documents()
        print(f"âœ… {len(documents)}ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸åˆæœŸåŒ–
        print("\nğŸ’¾ ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸åˆæœŸåŒ–")
        document_store, vector_store = setup_storage()
        print("âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¨ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’åˆæœŸåŒ–")
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: ã‚³ãƒ¼ãƒ‘ã‚¹æ§‹ç¯‰
        print("\nğŸ—ï¸ ã‚¹ãƒ†ãƒƒãƒ—3: ã‚³ãƒ¼ãƒ‘ã‚¹æ§‹ç¯‰")
        embedder = build_simple_corpus(documents, document_store, vector_store)
        
        # ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆ
        print("\nâš™ï¸ ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆ")
        query_engine = create_query_engine(document_store, vector_store, embedder)
        
        # ã‚¹ãƒ†ãƒƒãƒ—5: ã‚³ãƒ¼ãƒ‘ã‚¹çµ±è¨ˆæƒ…å ±
        show_corpus_stats(document_store, vector_store)
        
        # ã‚¹ãƒ†ãƒƒãƒ—6: è³ªç–‘å¿œç­”ãƒ†ã‚¹ãƒˆ
        print("\nğŸ§ª ã‚¹ãƒ†ãƒƒãƒ—5: è³ªç–‘å¿œç­”ãƒ†ã‚¹ãƒˆ")
        test_questions(query_engine)
        
        # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        print("\nğŸ‰ ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«1ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("\nğŸ“š å­¦ç¿’å†…å®¹:")
        print("   âœ… RAGã®åŸºæœ¬æ§‹æˆè¦ç´ ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã€ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ï¼‰")
        print("   âœ… Simple RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆLoad â†’ Chunk â†’ Vectorï¼‰")
        print("   âœ… QueryEngine ã‚’ä½¿ã£ãŸè³ªç–‘å¿œç­”")
        print("   âœ… TF-IDFåŸ‹ã‚è¾¼ã¿ã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢")
        
        print("\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("   â€¢ ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«2: ã‚³ãƒ¼ãƒ‘ã‚¹ç®¡ç†ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†")
        print("   â€¢ ã‚ˆã‚Šé«˜åº¦ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†æ©Ÿèƒ½")
        print("   â€¢ ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("\nğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:")
        print("   1. ä¾å­˜é–¢ä¿‚ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª: pip install -e .")
        print("   2. Python 3.10ä»¥ä¸Šã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹ç¢ºèª")
        print("   3. ãƒ¡ãƒ¢ãƒªå®¹é‡ãŒååˆ†ã‹ç¢ºèª")
        
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)