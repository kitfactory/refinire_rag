#!/usr/bin/env python3
"""
ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆãƒ†ã‚¹ãƒˆ

CorpusManagerã€QueryEngineã€QualityLabã®å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’çµ±åˆã—ãŸ
å®Œå…¨ãªRAGãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚
"""

import sys
from pathlib import Path
from typing import List, Dict, Any

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from refinire_rag.application.corpus_manager import CorpusManager, CorpusManagerConfig
from refinire_rag.application.query_engine import QueryEngine, QueryEngineConfig
from refinire_rag.models.document import Document
from refinire_rag.embedding import TFIDFEmbedder, TFIDFEmbeddingConfig
from refinire_rag.storage import InMemoryVectorStore, SQLiteDocumentStore
from refinire_rag.retrieval import SimpleRetriever, SimpleReranker, SimpleReader
from refinire_rag.processing import TestSuite, TestSuiteConfig, Evaluator, EvaluatorConfig
from refinire_rag.processing import ContradictionDetector, ContradictionDetectorConfig
from refinire_rag.processing import InsightReporter, InsightReporterConfig


def create_test_documents() -> List[Document]:
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
    
    documents = [
        Document(
            id="rag_overview",
            content="""
            # RAGï¼ˆRetrieval-Augmented Generationï¼‰æŠ€è¡“æ¦‚è¦
            
            RAGã¯æ¤œç´¢æ‹¡å¼µç”Ÿæˆã¨å‘¼ã°ã‚Œã‚‹é©æ–°çš„ãªAIæŠ€è¡“ã§ã™ã€‚
            ã“ã®æŠ€è¡“ã«ã‚ˆã‚Šã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®çŸ¥è­˜åˆ¶é™ã‚’å…‹æœã§ãã¾ã™ã€‚
            
            ## ä¸»è¦ãªåˆ©ç‚¹
            - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æœ€æ–°æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
            - ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå¹»è¦šï¼‰ã®å¤§å¹…æ¸›å°‘
            - é€æ˜æ€§ã¨èª¬æ˜å¯èƒ½æ€§ã®å‘ä¸Š
            - é«˜ã„ç²¾åº¦ã§ã®æƒ…å ±æ¤œç´¢ã¨ç”Ÿæˆ
            
            ## æŠ€è¡“çš„æ§‹æˆè¦ç´ 
            RAGã‚·ã‚¹ãƒ†ãƒ ã¯ä»¥ä¸‹ã®ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§æ§‹æˆã•ã‚Œã¾ã™ï¼š
            1. æ–‡æ›¸ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆLoaderï¼‰
            2. ãƒãƒ£ãƒ³ã‚«ãƒ¼ï¼ˆChunkerï¼‰
            3. ã‚¨ãƒ³ãƒ™ãƒƒãƒ€ãƒ¼ï¼ˆEmbedderï¼‰
            4. ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ï¼ˆVector Storeï¼‰
            5. ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ï¼ˆRetrieverï¼‰
            6. ãƒªãƒ©ãƒ³ã‚«ãƒ¼ï¼ˆRerankerï¼‰
            7. ãƒªãƒ¼ãƒ€ãƒ¼ï¼ˆReader/Generatorï¼‰
            """,
            metadata={"category": "æŠ€è¡“è§£èª¬", "source": "å†…éƒ¨æ–‡æ›¸", "version": "1.0"}
        ),
        
        Document(
            id="evaluation_metrics",
            content="""
            # RAGã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡æŒ‡æ¨™
            
            RAGã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½è©•ä¾¡ã«ã¯å¤šè§’çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã™ã€‚
            
            ## ç²¾åº¦æŒ‡æ¨™
            - **Accuracy**: æ­£ç­”ç‡
            - **Precision**: é©åˆç‡
            - **Recall**: å†ç¾ç‡  
            - **F1-Score**: ç²¾åº¦ã¨å†ç¾ç‡ã®èª¿å’Œå¹³å‡
            
            ## åŠ¹ç‡æ€§æŒ‡æ¨™
            - **Response Time**: å¿œç­”æ™‚é–“
            - **Throughput**: ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ
            - **Resource Usage**: ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡
            
            ## å“è³ªæŒ‡æ¨™
            - **Relevance**: é–¢é€£æ€§
            - **Completeness**: å®Œå…¨æ€§
            - **Consistency**: ä¸€è²«æ€§
            - **Factual Accuracy**: äº‹å®Ÿæ­£ç¢ºæ€§
            
            ## ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“æŒ‡æ¨™
            - **User Satisfaction**: ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦
            - **Task Completion Rate**: ã‚¿ã‚¹ã‚¯å®Œäº†ç‡
            - **Error Recovery**: ã‚¨ãƒ©ãƒ¼å›å¾©èƒ½åŠ›
            
            è©•ä¾¡ã¯ç¶™ç¶šçš„ã«å®Ÿæ–½ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã®æ”¹å–„ã«æ´»ç”¨ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚
            """,
            metadata={"category": "è©•ä¾¡", "source": "ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹", "version": "1.1"}
        ),
        
        Document(
            id="implementation_challenges", 
            content="""
            # RAGå®Ÿè£…ã«ãŠã‘ã‚‹èª²é¡Œã¨è§£æ±ºç­–
            
            RAGã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ã§ã¯æ§˜ã€…ãªæŠ€è¡“çš„èª²é¡Œã«ç›´é¢ã—ã¾ã™ã€‚
            
            ## ãƒ‡ãƒ¼ã‚¿å“è³ªã®èª²é¡Œ
            - **å•é¡Œ**: ä¸æ­£ç¢ºã¾ãŸã¯å¤ã„æƒ…å ±ã®æ··å…¥
            - **è§£æ±ºç­–**: ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨å®šæœŸçš„æ›´æ–°ãƒ—ãƒ­ã‚»ã‚¹
            
            ## æ¤œç´¢æ€§èƒ½ã®èª²é¡Œ
            - **å•é¡Œ**: å¤§è¦æ¨¡ã‚³ãƒ¼ãƒ‘ã‚¹ã§ã®é…ã„æ¤œç´¢é€Ÿåº¦
            - **è§£æ±ºç­–**: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥
            
            ## ä¸€è²«æ€§ã®èª²é¡Œ
            - **å•é¡Œ**: çŸ›ç›¾ã™ã‚‹æƒ…å ±æºã‹ã‚‰ã®å›ç­”ç”Ÿæˆ
            - **è§£æ±ºç­–**: çŸ›ç›¾æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã¨ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
            
            ## ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®èª²é¡Œ
            - **å•é¡Œ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°å¢—åŠ ã«ä¼´ã†æ€§èƒ½åŠ£åŒ–
            - **è§£æ±ºç­–**: åˆ†æ•£ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨è² è·åˆ†æ•£
            
            ## ã‚³ã‚¹ãƒˆæœ€é©åŒ–
            å®Ÿè£…ã‚³ã‚¹ãƒˆã¯æ¯”è¼ƒçš„ä½ãæŠ‘ãˆã‚‰ã‚Œã¾ã™ãŒã€é‹ç”¨ã‚³ã‚¹ãƒˆã®ç®¡ç†ãŒé‡è¦ã§ã™ã€‚
            ã‚¯ãƒ©ã‚¦ãƒ‰ãƒªã‚½ãƒ¼ã‚¹ã®åŠ¹ç‡çš„æ´»ç”¨ã¨è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚
            """,
            metadata={"category": "å®Ÿè£…", "source": "æŠ€è¡“ã‚¬ã‚¤ãƒ‰", "version": "1.2"}
        ),
        
        Document(
            id="future_directions",
            content="""
            # RAGæŠ€è¡“ã®ä»Šå¾Œã®ç™ºå±•æ–¹å‘
            
            RAGæŠ€è¡“ã¯æ€¥é€Ÿã«é€²åŒ–ã—ã¦ãŠã‚Šã€ä»¥ä¸‹ã®æ–¹å‘æ€§ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã¾ã™ã€‚
            
            ## ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAG
            ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã§ãªãã€ç”»åƒã€éŸ³å£°ã€å‹•ç”»ãªã©ã®å¤šæ§˜ãªãƒ¡ãƒ‡ã‚£ã‚¢ã‚’çµ±åˆã—ãŸ
            æ¤œç´¢æ‹¡å¼µç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ãŒé–‹ç™ºã•ã‚Œã¦ã„ã¾ã™ã€‚
            
            ## ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨RAGã®èåˆ
            äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨RAGã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€
            ã‚ˆã‚Šé«˜ç²¾åº¦ã§å°‚é–€çš„ãªçŸ¥è­˜ã‚’æ´»ç”¨ã§ãã‚‹ã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿç¾ã•ã‚Œã¾ã™ã€‚
            
            ## ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰ç¶™ç¶šçš„ã«å­¦ç¿’ã—ã€
            æ¤œç´¢ã¨ç”Ÿæˆã®å“è³ªã‚’å‹•çš„ã«æ”¹å–„ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã€‚
            
            ## ã‚¨ãƒƒã‚¸ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°å¯¾å¿œ
            è»½é‡åŒ–ã•ã‚ŒãŸRAGãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šã€ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ã§ã®
            ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã§é«˜é€Ÿãªæƒ…å ±æ¤œç´¢ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚
            
            ã“ã‚Œã‚‰ã®æŠ€è¡“é€²æ­©ã«ã‚ˆã‚Šã€RAGã¯ã‚ˆã‚Šå®Ÿç”¨çš„ã§
            å¤šæ§˜ãªç”¨é€”ã«é©ç”¨å¯èƒ½ãªæŠ€è¡“ã¸ã¨ç™ºå±•ã—ã¦ã„ã¾ã™ã€‚
            """,
            metadata={"category": "æœªæ¥äºˆæ¸¬", "source": "ç ”ç©¶è«–æ–‡", "version": "1.0"}
        )
    ]
    
    return documents


def create_test_queries() -> List[Dict[str, Any]]:
    """ãƒ†ã‚¹ãƒˆç”¨ã‚¯ã‚¨ãƒªã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
    
    queries = [
        {
            "query": "RAGã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "expected_type": "definition",
            "category": "åŸºæœ¬æ¦‚å¿µ"
        },
        {
            "query": "RAGã‚·ã‚¹ãƒ†ãƒ ã®ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æ•™ãˆã¦ãã ã•ã„",
            "expected_type": "enumeration", 
            "category": "æŠ€è¡“è©³ç´°"
        },
        {
            "query": "RAGã®è©•ä¾¡æŒ‡æ¨™ã«ã¯ã©ã®ã‚ˆã†ãªã‚‚ã®ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            "expected_type": "classification",
            "category": "è©•ä¾¡æ–¹æ³•"
        },
        {
            "query": "RAGå®Ÿè£…æ™‚ã®ä¸»ãªèª²é¡Œã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "expected_type": "problem_identification",
            "category": "å®Ÿè£…"
        },
        {
            "query": "RAGæŠ€è¡“ã®å°†æ¥æ€§ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„",
            "expected_type": "analysis",
            "category": "å°†æ¥å±•æœ›"
        },
        {
            "query": "RAGã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹æ–¹æ³•ã¯ï¼Ÿ",
            "expected_type": "solution",
            "category": "æœ€é©åŒ–"
        },
        {
            "query": "ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "expected_type": "advanced_concept",
            "category": "å…ˆç«¯æŠ€è¡“"
        },
        {
            "query": "RAGã®ã‚³ã‚¹ãƒˆã¯ã©ã®ç¨‹åº¦ã§ã™ã‹ï¼Ÿ",
            "expected_type": "quantitative",
            "category": "é‹ç”¨"
        }
    ]
    
    return queries


def setup_rag_pipeline() -> tuple:
    """å®Œå…¨ãªRAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    
    print("ğŸ”§ RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
    
    # 1. CorpusManagerè¨­å®š
    from refinire_rag.chunking import ChunkingConfig
    
    corpus_config = CorpusManagerConfig(
        enable_processing=True,
        enable_chunking=True,
        enable_embedding=True,
        chunking_config=ChunkingConfig(
            chunk_size=200,
            overlap=50,
            split_by_sentence=True
        )
    )
    
    # 2. QueryEngineè¨­å®š
    query_config = QueryEngineConfig(
        retriever_top_k=10,
        reranker_top_k=5,
        enable_query_normalization=True,
        include_sources=True,
        include_confidence=True
    )
    
    # 3. ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸åˆæœŸåŒ–
    vector_store = InMemoryVectorStore()
    document_store = SQLiteDocumentStore(":memory:")
    
    # 4. åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«è¨­å®š
    embedding_config = TFIDFEmbeddingConfig(min_df=1, max_df=1.0)
    embedder = TFIDFEmbedder(config=embedding_config)
    
    # 5. æ¤œç´¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
    retriever = SimpleRetriever(vector_store=vector_store, embedder=embedder)
    reranker = SimpleReranker()
    reader = SimpleReader()
    
    # 6. ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ 
    # CorpusManagerConfigã«å¤–éƒ¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’è¨­å®š
    corpus_config.document_store = document_store
    corpus_config.vector_store = vector_store
    corpus_config.embedder = embedder
    
    corpus_manager = CorpusManager(config=corpus_config)
    
    query_engine = QueryEngine(
        document_store=document_store,
        vector_store=vector_store,
        retriever=retriever,
        reader=reader,
        reranker=reranker,
        config=query_config
    )
    
    print("âœ… RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")
    
    return corpus_manager, query_engine, embedder


def setup_quality_lab() -> tuple:
    """QualityLabã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    
    print("ğŸ”¬ QualityLabã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
    
    # TestSuiteè¨­å®š
    test_config = TestSuiteConfig()
    
    # Evaluatorè¨­å®š
    eval_config = EvaluatorConfig()
    
    # ContradictionDetectorè¨­å®š
    contradiction_config = ContradictionDetectorConfig()
    
    # InsightReporterè¨­å®š
    insight_config = InsightReporterConfig()
    
    # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆä½œæˆ
    test_suite = TestSuite(test_config)
    evaluator = Evaluator(eval_config)
    contradiction_detector = ContradictionDetector(contradiction_config)
    insight_reporter = InsightReporter(insight_config)
    
    print("âœ… QualityLabã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")
    
    return test_suite, evaluator, contradiction_detector, insight_reporter


def test_corpus_building(corpus_manager: CorpusManager, documents: List[Document]) -> bool:
    """ã‚³ãƒ¼ãƒ‘ã‚¹æ§‹ç¯‰ã®ãƒ†ã‚¹ãƒˆ"""
    
    print("\nğŸ“š ã‚³ãƒ¼ãƒ‘ã‚¹æ§‹ç¯‰ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    try:
        # æ–‡æ›¸ã®å‡¦ç†
        print(f"ğŸ“„ {len(documents)}ä»¶ã®æ–‡æ›¸ã‚’å‡¦ç†ä¸­...")
        processed_docs = corpus_manager.process_documents(documents)
        
        # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        print("ğŸ”§ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­...")
        embedded_docs = corpus_manager.embed_documents(processed_docs)
        
        # æ–‡æ›¸ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
        print("ğŸ’¾ æ–‡æ›¸ã‚’ä¿å­˜ä¸­...")
        stored_count = corpus_manager.store_documents(processed_docs)
        
        # çµ±è¨ˆç¢ºèª
        stats = corpus_manager.get_corpus_stats()
        
        print(f"âœ… ã‚³ãƒ¼ãƒ‘ã‚¹æ§‹ç¯‰å®Œäº†:")
        print(f"   - å‡¦ç†æ¸ˆã¿æ–‡æ›¸æ•°: {len(processed_docs)}")
        print(f"   - åŸ‹ã‚è¾¼ã¿ç”Ÿæˆæ•°: {len(embedded_docs)}")
        print(f"   - ä¿å­˜æ¸ˆã¿æ–‡æ›¸æ•°: {stored_count}")
        print(f"   - å‡¦ç†çµ±è¨ˆ: {stats}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚³ãƒ¼ãƒ‘ã‚¹æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_query_processing(query_engine: QueryEngine, queries: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ã‚¯ã‚¨ãƒªå‡¦ç†ã®ãƒ†ã‚¹ãƒˆ"""
    
    print("\nğŸ” ã‚¯ã‚¨ãƒªå‡¦ç†ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    query_results = []
    
    for i, query_data in enumerate(queries, 1):
        query = query_data["query"]
        category = query_data["category"]
        
        print(f"\nğŸ“ ã‚¯ã‚¨ãƒª {i}: {query}")
        print(f"ã‚«ãƒ†ã‚´ãƒª: {category}")
        
        try:
            # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            import time
            start_time = time.time()
            
            result = query_engine.answer(query)
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            # çµæœã®è¨˜éŒ²
            query_result = {
                "query_id": f"test_query_{i}",
                "query": query,
                "category": category,
                "answer": result.answer,
                "sources": len(result.sources),
                "confidence": result.confidence,
                "processing_time": processing_time,
                "success": result.confidence > 0.3,
                "metadata": query_data
            }
            
            query_results.append(query_result)
            
            # çµæœè¡¨ç¤º
            print(f"âœ… å¿œç­”: {result.answer[:100]}...")
            print(f"   ä¿¡é ¼åº¦: {result.confidence:.3f}")
            print(f"   ã‚½ãƒ¼ã‚¹æ•°: {len(result.sources)}")
            print(f"   å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’")
            
        except Exception as e:
            print(f"âŒ ã‚¯ã‚¨ãƒªå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ã‚¨ãƒ©ãƒ¼çµæœã®è¨˜éŒ²
            query_result = {
                "query_id": f"test_query_{i}",
                "query": query,
                "category": category,
                "answer": f"ã‚¨ãƒ©ãƒ¼: {str(e)}",
                "sources": 0,
                "confidence": 0.0,
                "processing_time": 0.0,
                "success": False,
                "error": str(e)
            }
            
            query_results.append(query_result)
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    success_count = sum(1 for r in query_results if r["success"])
    avg_confidence = sum(r["confidence"] for r in query_results) / len(query_results)
    avg_time = sum(r["processing_time"] for r in query_results) / len(query_results)
    
    print(f"\nğŸ“Š ã‚¯ã‚¨ãƒªå‡¦ç†ã‚µãƒãƒªãƒ¼:")
    print(f"   - æˆåŠŸç‡: {success_count}/{len(query_results)} ({success_count/len(query_results):.1%})")
    print(f"   - å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.3f}")
    print(f"   - å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.3f}ç§’")
    
    return query_results


def test_quality_evaluation(
    quality_components: tuple,
    documents: List[Document],
    query_results: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """å“è³ªè©•ä¾¡ã®ãƒ†ã‚¹ãƒˆ"""
    
    print("\nğŸ”¬ å“è³ªè©•ä¾¡ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    test_suite, evaluator, contradiction_detector, insight_reporter = quality_components
    evaluation_results = {}
    
    try:
        # 1. è‡ªå‹•ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ
        print("\n1ï¸âƒ£ è‡ªå‹•ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ")
        test_documents = []
        
        for doc in documents[:2]:  # æœ€åˆã®2æ–‡æ›¸ã‚’ãƒ†ã‚¹ãƒˆ
            test_results = test_suite.process(doc)
            test_documents.extend(test_results)
            
            if test_results:
                metadata = test_results[0].metadata
                print(f"   ğŸ“‹ {doc.id}: {metadata.get('generated_cases_count', 0)}ä»¶ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ")
        
        # 2. çŸ›ç›¾æ¤œå‡º
        print("\n2ï¸âƒ£ çŸ›ç›¾æ¤œå‡ºåˆ†æ")
        contradiction_documents = []
        
        for doc in documents:
            contradiction_results = contradiction_detector.process(doc)
            contradiction_documents.extend(contradiction_results)
            
            if contradiction_results:
                metadata = contradiction_results[0].metadata
                claims = metadata.get('claims_extracted', 0)
                contradictions = metadata.get('contradictions_found', 0)
                print(f"   ğŸ” {doc.id}: {claims}ã‚¯ãƒ¬ãƒ¼ãƒ , {contradictions}çŸ›ç›¾")
        
        # 3. ã‚¯ã‚¨ãƒªçµæœã®è©•ä¾¡ç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ
        print("\n3ï¸âƒ£ ã‚¯ã‚¨ãƒªçµæœè©•ä¾¡")
        
        # ã‚¯ã‚¨ãƒªçµæœã‚’ãƒ†ã‚¹ãƒˆçµæœãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¤‰æ›
        test_results_content = "# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œçµæœ\n\n"
        
        for result in query_results:
            status = "âœ… PASS" if result["success"] else "âŒ FAIL"
            test_results_content += f"## {status} {result['query_id']}\n"
            test_results_content += f"**Query**: {result['query']}\n"
            test_results_content += f"**Confidence**: {result['confidence']}\n"
            test_results_content += f"**Processing Time**: {result['processing_time']}s\n"
            test_results_content += f"**Sources Found**: {result['sources']}\n\n"
        
        test_results_doc = Document(
            id="end_to_end_test_results",
            content=test_results_content,
            metadata={
                "processing_stage": "test_execution",
                "tests_run": len(query_results),
                "tests_passed": sum(1 for r in query_results if r["success"]),
                "success_rate": sum(1 for r in query_results if r["success"]) / len(query_results),
                "source_document_id": "end_to_end_test"
            }
        )
        
        # è©•ä¾¡å®Ÿè¡Œ
        evaluation_documents = evaluator.process(test_results_doc)
        
        if evaluation_documents:
            eval_metadata = evaluation_documents[0].metadata
            metrics_count = eval_metadata.get('metrics_computed', 0)
            overall_score = eval_metadata.get('overall_score', 0)
            print(f"   ğŸ“Š è©•ä¾¡å®Œäº†: {metrics_count}ãƒ¡ãƒˆãƒªã‚¯ã‚¹, ç·åˆã‚¹ã‚³ã‚¢{overall_score:.2f}")
        
        # 4. ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ
        print("\n4ï¸âƒ£ ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ")
        insight_documents = []
        
        for eval_doc in evaluation_documents:
            insight_results = insight_reporter.process(eval_doc)
            insight_documents.extend(insight_results)
            
            if insight_results:
                metadata = insight_results[0].metadata
                insights = metadata.get('insights_generated', 0)
                critical = metadata.get('critical_insights', 0)
                health_score = metadata.get('overall_health_score', 0)
                print(f"   ğŸ’¡ ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ: {insights}ä»¶({critical}é‡è¦), ãƒ˜ãƒ«ã‚¹ã‚¹ã‚³ã‚¢{health_score:.2f}")
        
        # 5. çµæœã‚µãƒãƒªãƒ¼
        evaluation_results = {
            "test_generation": {
                "documents_processed": len(test_documents),
                "test_cases_generated": sum(d.metadata.get('generated_cases_count', 0) for d in test_documents)
            },
            "contradiction_detection": {
                "documents_analyzed": len(contradiction_documents),
                "total_claims": sum(d.metadata.get('claims_extracted', 0) for d in contradiction_documents),
                "total_contradictions": sum(d.metadata.get('contradictions_found', 0) for d in contradiction_documents)
            },
            "evaluation": {
                "queries_evaluated": len(query_results),
                "overall_score": evaluation_documents[0].metadata.get('overall_score', 0) if evaluation_documents else 0,
                "metrics_computed": evaluation_documents[0].metadata.get('metrics_computed', 0) if evaluation_documents else 0
            },
            "insights": {
                "insights_generated": insight_documents[0].metadata.get('insights_generated', 0) if insight_documents else 0,
                "critical_insights": insight_documents[0].metadata.get('critical_insights', 0) if insight_documents else 0,
                "health_score": insight_documents[0].metadata.get('overall_health_score', 0) if insight_documents else 0
            }
        }
        
        return evaluation_results
        
    except Exception as e:
        print(f"âŒ å“è³ªè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return {"error": str(e)}


def test_system_integration() -> bool:
    """ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    
    print("\nğŸš€ ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    try:
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“ã®ç›¸äº’ä½œç”¨ãƒ†ã‚¹ãƒˆ
        print("ğŸ”— ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“ç›¸äº’ä½œç”¨ãƒ†ã‚¹ãƒˆ")
        
        # 1. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
        try:
            import psutil
            import os
            process = psutil.Process(os.getpid())
            memory_before = process.memory_info().rss / 1024 / 1024  # MB
            memory_monitoring = True
        except ImportError:
            print("   âš ï¸ psutilãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            memory_before = 0
            memory_monitoring = False
        
        # 2. ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
        print("   ğŸ“Š ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ç›£è¦–é–‹å§‹")
        
        # 3. ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ†ã‚¹ãƒˆ
        print("   ğŸ”§ ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ†ã‚¹ãƒˆ")
        
        # ç„¡åŠ¹ãªã‚¯ã‚¨ãƒªã®ãƒ†ã‚¹ãƒˆ
        corpus_manager, query_engine, _ = setup_rag_pipeline()
        
        try:
            result = query_engine.answer("")  # ç©ºã‚¯ã‚¨ãƒª
            print("   âŒ ç©ºã‚¯ã‚¨ãƒªãŒä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã¾ã›ã‚“ã§ã—ãŸ")
        except:
            print("   âœ… ç©ºã‚¯ã‚¨ãƒªãŒé©åˆ‡ã«ãƒãƒ³ãƒ‰ãƒ«ã•ã‚Œã¾ã—ãŸ")
        
        try:
            result = query_engine.answer("x" * 1000)  # é•·ã™ãã‚‹ã‚¯ã‚¨ãƒª
            print(f"   âš ï¸ é•·ã„ã‚¯ã‚¨ãƒªãŒå‡¦ç†ã•ã‚Œã¾ã—ãŸ (ä¿¡é ¼åº¦: {result.confidence:.3f})")
        except:
            print("   âœ… é•·ã„ã‚¯ã‚¨ãƒªãŒé©åˆ‡ã«ãƒãƒ³ãƒ‰ãƒ«ã•ã‚Œã¾ã—ãŸ")
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
        if memory_monitoring:
            memory_after = process.memory_info().rss / 1024 / 1024  # MB
            memory_diff = memory_after - memory_before
            
            print(f"   ğŸ“Š ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_after:.1f}MB (å·®åˆ†: +{memory_diff:.1f}MB)")
            
            if memory_diff > 100:  # 100MBä»¥ä¸Šã®å¢—åŠ ã¯è­¦å‘Š
                print("   âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤§å¹…ã«å¢—åŠ ã—ã¾ã—ãŸ")
            else:
                print("   âœ… ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯é©åˆ‡ãªç¯„å›²å†…ã§ã™")
        else:
            print("   ğŸ“Š ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False


def main() -> bool:
    """ãƒ¡ã‚¤ãƒ³çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    
    print("ğŸš€ ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    # ãƒ†ã‚¹ãƒˆãƒ•ãƒ©ã‚°
    test_results = {
        "corpus_building": False,
        "query_processing": False,
        "quality_evaluation": False,
        "system_integration": False
    }
    
    try:
        # 1. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
        print("ğŸ“‹ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­...")
        documents = create_test_documents()
        queries = create_test_queries()
        print(f"âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {len(documents)}æ–‡æ›¸, {len(queries)}ã‚¯ã‚¨ãƒª")
        
        # 2. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        corpus_manager, query_engine, embedder = setup_rag_pipeline()
        quality_components = setup_quality_lab()
        
        # 3. ã‚³ãƒ¼ãƒ‘ã‚¹æ§‹ç¯‰ãƒ†ã‚¹ãƒˆ
        test_results["corpus_building"] = test_corpus_building(corpus_manager, documents)
        
        # 4. ã‚¯ã‚¨ãƒªå‡¦ç†ãƒ†ã‚¹ãƒˆ
        if test_results["corpus_building"]:
            query_results = test_query_processing(query_engine, queries)
            test_results["query_processing"] = len(query_results) > 0
            
            # 5. å“è³ªè©•ä¾¡ãƒ†ã‚¹ãƒˆ
            if test_results["query_processing"]:
                evaluation_results = test_quality_evaluation(
                    quality_components, documents, query_results
                )
                test_results["quality_evaluation"] = "error" not in evaluation_results
        
        # 6. ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ
        test_results["system_integration"] = test_system_integration()
        
        # 7. æœ€çµ‚çµæœãƒ¬ãƒãƒ¼ãƒˆ
        print("\nğŸ“‹ æœ€çµ‚ãƒ†ã‚¹ãƒˆçµæœ")
        print("=" * 50)
        
        total_tests = len(test_results)
        passed_tests = sum(test_results.values())
        
        for test_name, passed in test_results.items():
            status = "âœ… PASS" if passed else "âŒ FAIL"
            print(f"{status} {test_name}")
        
        print(f"\nğŸ“Š ç·åˆçµæœ: {passed_tests}/{total_tests} ãƒ†ã‚¹ãƒˆé€šé ({passed_tests/total_tests:.1%})")
        
        if passed_tests == total_tests:
            print("\nğŸ‰ å…¨ãƒ†ã‚¹ãƒˆé€šéï¼ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
            
            # æ¨å¥¨äº‹é …
            print("\nğŸ¯ ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´:")
            print("   âœ… ã‚³ãƒ¼ãƒ‘ã‚¹ç®¡ç†: æ–‡æ›¸ã®è¿½åŠ ã€æ­£è¦åŒ–ã€ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã€åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ")
            print("   âœ… ã‚¯ã‚¨ãƒªå‡¦ç†: æ¤œç´¢ã€ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€å›ç­”ç”Ÿæˆ")
            print("   âœ… å“è³ªè©•ä¾¡: è‡ªå‹•ãƒ†ã‚¹ãƒˆã€çŸ›ç›¾æ¤œå‡ºã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ã€ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ")
            print("   âœ… çµ±åˆæ€§: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†")
            
            print("\nğŸ“š æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
            print("   ğŸ”¹ æœ¬ç•ªç’°å¢ƒã¸ã®å±•é–‹æº–å‚™")
            print("   ğŸ”¹ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
            print("   ğŸ”¹ ç›£è¦–ã¨ãƒ­ã‚®ãƒ³ã‚°ã®å®Ÿè£…")
            print("   ğŸ”¹ ãƒ¦ãƒ¼ã‚¶ãƒ¼å—ã‘å…¥ã‚Œãƒ†ã‚¹ãƒˆ")
            
        else:
            print("\nâš ï¸ ä¸€éƒ¨ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ã®ä¿®æ­£ãŒå¿…è¦ã§ã™")
            
            # å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã®ç‰¹å®š
            failed_tests = [name for name, passed in test_results.items() if not passed]
            print(f"å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆ: {', '.join(failed_tests)}")
        
        return passed_tests == total_tests
        
    except Exception as e:
        print(f"\nâŒ çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)