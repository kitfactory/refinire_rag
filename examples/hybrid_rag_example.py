#!/usr/bin/env python3
"""
Simple Hybrid RAG Example - 3 Clear Steps

ã“ã®ä¾‹ã¯ã€refinire-ragãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã£ãŸåŸºæœ¬çš„ãªRAGãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ã€
4ã¤ã®æ˜ç¢ºãªã‚¹ãƒ†ãƒƒãƒ—ã§ç¤ºã—ã¾ã™ï¼š

1. ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆEnvironment Variable Setupï¼‰
2. ã‚³ãƒ¼ãƒ‘ã‚¹ã®ä½œæˆï¼ˆCorpus Creationï¼‰  
3. ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã§ã®æ¤œç´¢ï¼ˆQuery Engine Searchï¼‰
4. å“è³ªè©•ä¾¡ï¼ˆQuality Evaluation with QualityLabï¼‰

Requirements:
- Optional: refinire-rag[bm25,chroma] for hybrid search capabilities
- Environment variables for LLM integration (OpenAI recommended)

ä½¿ç”¨æ–¹æ³• / Usage:
```bash
# OpenAI API keyã‚’è¨­å®šï¼ˆæ¨å¥¨ï¼‰
export OPENAI_API_KEY="your-api-key-here"

# ãƒ—ãƒ­ã‚°ãƒ©ãƒ å®Ÿè¡Œ
python examples/hybrid_rag_example.py
```
"""

import os
import sys
import shutil
import glob
from pathlib import Path

# Add src to Python path for direct execution
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from refinire_rag.application import CorpusManager, QueryEngine, QualityLab
from refinire_rag.registry import PluginRegistry

def cleanup_existing_data():
    """æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    print("ğŸ§¹ Cleaning up existing data...")
    
    cleanup_targets = [
        "./business_rag.db", "./data/documents.db", "./refinire/rag/",
        "./bm25s_index/", "./bm25s_data/", "./data/bm25s/", "./data/bm25s_index/", 
        "*.bm25s", "*.index", "./data/bm25s_keyword_store.db"
    ]
    
    cleaned_count = 0
    for target in cleanup_targets:
        if "*" in target:
            for file_path in glob.glob(target):
                try:
                    Path(file_path).unlink()
                    cleaned_count += 1
                except Exception:
                    pass
        else:
            target_path = Path(target)
            if target_path.exists():
                try:
                    if target_path.is_file():
                        target_path.unlink()
                    else:
                        shutil.rmtree(target_path)
                    cleaned_count += 1
                except Exception:
                    pass
    
    print(f"   âœ… Cleaned up {cleaned_count} items" if cleaned_count > 0 else "   âœ¨ Starting fresh")

def step1_setup_environment():
    """
    ã‚¹ãƒ†ãƒƒãƒ—1: ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
    
    refinire-ragãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ã£ã¦å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è‡ªå‹•è¨­å®šã—ã¾ã™ã€‚
    ã“ã“ã§ã¯åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’æ¤œå‡ºã—ã€æœ€é©ãªè¨­å®šã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã—ã¾ã™ã€‚
    """
    print("\n" + "="*60)
    print("ğŸ”§ STEP 1: Environment Variable Setup")
    print("="*60)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    cleanup_existing_data()
    
    # åŸºæœ¬è¨­å®š: Document Storeï¼ˆæ–‡æ›¸ä¿å­˜ï¼‰
    print("\nğŸ“ Setting up Document Store...")
    os.environ.setdefault("REFINIRE_RAG_DOCUMENT_STORES", "sqlite")
    os.environ.setdefault("REFINIRE_RAG_SQLITE_DB_PATH", "./business_rag.db")
    print("   âœ… SQLite document store configured")
    
    # Embedderè¨­å®š: ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ç”¨ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
    print("\nğŸ§  Setting up Embedder...")
    if os.environ.get("OPENAI_API_KEY"):
        os.environ.setdefault("REFINIRE_RAG_EMBEDDERS", "openai")
        print("   âœ… OpenAI embedder configured (high quality)")
    else:
        os.environ.setdefault("REFINIRE_RAG_EMBEDDERS", "tfidf")
        print("   âš ï¸  TF-IDF embedder configured (no API key required)")
        print("      ğŸ’¡ For better results, set OPENAI_API_KEY environment variable")
    
    # ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
    print("\nğŸ“¦ Checking Plugin Availability...")
    available_plugins = {
        'chroma': PluginRegistry.get_plugin_class('vector_stores', 'chroma') is not None,
        'bm25s': PluginRegistry.get_plugin_class('keyword_stores', 'bm25s_keyword') is not None
    }
    
    # Vector Storeè¨­å®š: ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢
    if available_plugins['chroma']:
        os.environ.setdefault("REFINIRE_RAG_VECTOR_STORES", "chroma")
        print("   âœ… Chroma vector store configured (external plugin)")
    else:
        os.environ.setdefault("REFINIRE_RAG_VECTOR_STORES", "inmemory_vector")
        print("   âœ… InMemory vector store configured (built-in)")
    
    # Keyword Storeè¨­å®š: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
    if available_plugins['bm25s']:
        os.environ.setdefault("REFINIRE_RAG_KEYWORD_STORES", "bm25s_keyword")
        os.environ.setdefault("REFINIRE_RAG_BM25S_INDEX_PATH", "./data/bm25s_index")
        print("   âœ… BM25s keyword store configured (external plugin)")
    else:
        print("   âš ï¸  No keyword store available (install refinire-rag[bm25] for hybrid search)")
    
    # Hybrid Searchå¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
    if available_plugins['chroma'] and available_plugins['bm25s']:
        print("\nğŸ¯ Configuring Hybrid Search Components...")
        
        # Rerankerè¨­å®š: æ¤œç´¢çµæœã®å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        available_rerankers = PluginRegistry.list_available_plugins('rerankers')
        has_openai = bool(os.environ.get("OPENAI_API_KEY"))
        
        if "llm" in available_rerankers and has_openai:
            os.environ.setdefault("REFINIRE_RAG_RERANKERS", "llm")
            print("   âœ… LLM reranker configured (highest quality)")
        elif "rrf" in available_rerankers:
            os.environ.setdefault("REFINIRE_RAG_RERANKERS", "rrf")
            print("   âœ… RRF reranker configured (mathematical fusion)")
        elif "heuristic" in available_rerankers:
            os.environ.setdefault("REFINIRE_RAG_RERANKERS", "heuristic")
            print("   âœ… Heuristic reranker configured (keyword-based)")
        
        # Answer Synthesizerè¨­å®š: å›ç­”ç”Ÿæˆ
        os.environ.setdefault("REFINIRE_RAG_SYNTHESIZERS", "answer")
        print("   âœ… Answer synthesizer configured")
        
        if has_openai:
            os.environ.setdefault("REFINIRE_RAG_LLM_MODEL", "gpt-4o-mini")
            print("   âœ… LLM model: gpt-4o-mini")
        
        print("   ğŸš€ Hybrid search ready: Vector + Keyword + Reranking + LLM")
    else:
        # Simple retrievalè¨­å®š
        os.environ.setdefault("REFINIRE_RAG_RETRIEVERS", "simple")
        print("   âœ… Simple retrieval configured")
    
    print(f"\nğŸ“‹ Environment Setup Summary:")
    print(f"   â€¢ Document Store: {os.environ.get('REFINIRE_RAG_DOCUMENT_STORES', 'None')}")
    print(f"   â€¢ Vector Store: {os.environ.get('REFINIRE_RAG_VECTOR_STORES', 'None')}")
    print(f"   â€¢ Keyword Store: {os.environ.get('REFINIRE_RAG_KEYWORD_STORES', 'None')}")
    print(f"   â€¢ Reranker: {os.environ.get('REFINIRE_RAG_RERANKERS', 'None')}")
    print(f"   â€¢ Synthesizer: {os.environ.get('REFINIRE_RAG_SYNTHESIZERS', 'None')}")
    print(f"   â€¢ Embedder: {os.environ.get('REFINIRE_RAG_EMBEDDERS', 'None')}")
    
    return available_plugins

def step2_create_corpus():
    """
    ã‚¹ãƒ†ãƒƒãƒ—2: CorpusManagerã§ã‚³ãƒ¼ãƒ‘ã‚¹ä½œæˆ
    
    CorpusManagerã¯ç’°å¢ƒå¤‰æ•°ã®è¨­å®šã«åŸºã¥ã„ã¦è‡ªå‹•çš„ã«ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã€
    ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆæ¤œç´¢å¯èƒ½ãªæ–‡æ›¸é›†åˆï¼‰ã‚’ä½œæˆã—ã¾ã™ã€‚
    """
    print("\n" + "="*60)
    print("ğŸ“š STEP 2: Corpus Creation with CorpusManager")
    print("="*60)
        
    # CorpusManagerä½œæˆï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•è¨­å®šï¼‰
    corpus_manager = CorpusManager()
    data_path = Path(__file__).parent.parent / "tests" / "data" / "business_dataset"
    
    # æ–‡æ›¸ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    import_stats = corpus_manager.import_original_documents(
        corpus_name="business_knowledge",
        directory=str(data_path),
        glob="*.txt"
    )
    print(f"   âœ… Documents imported: {import_stats.total_documents_created}")
    print(f"   â±ï¸  Import time: {import_stats.total_processing_time:.2f}s")
    
    # ã‚³ãƒ¼ãƒ‘ã‚¹æ§‹ç¯‰ï¼ˆåŸ‹ã‚è¾¼ã¿ç”Ÿæˆãƒ»ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼‰
    print(f"\nğŸ”¨ Building corpus with embeddings and indexing...")
    build_stats = corpus_manager.rebuild_corpus_from_original(
        corpus_name="business_knowledge"
    )
    print(f"   âœ… Chunks created: {build_stats.total_chunks_created}")
    print(f"   â±ï¸  Build time: {build_stats.total_processing_time:.2f}s")
    
    # ã‚³ãƒ¼ãƒ‘ã‚¹æƒ…å ±è¡¨ç¤º
    print(f"\nğŸ“ˆ Corpus Information:")
    print(f"   ğŸ·ï¸  Name: business_knowledge")
    print(f"   ğŸ“„ Documents: {import_stats.total_documents_created}")
    print(f"   ğŸ“ Chunks: {build_stats.total_chunks_created}")
    print(f"   ğŸ” Retrievers: {len(corpus_manager.retrievers)}")
    print(f"   ğŸ§  Embedder: {os.environ.get('REFINIRE_RAG_EMBEDDERS')}")
    
    return corpus_manager

def step3_query_engine_search():
    """
    ã‚¹ãƒ†ãƒƒãƒ—3: QueryEngineã§æ¤œç´¢ãƒ»å›ç­”ç”Ÿæˆ
    
    QueryEngineã‚‚ç’°å¢ƒå¤‰æ•°ã®è¨­å®šã«åŸºã¥ã„ã¦è‡ªå‹•çš„ã«ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã€
    ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦æ¤œç´¢ãƒ»å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ»å›ç­”ç”Ÿæˆã‚’è¡Œã„ã¾ã™ã€‚
    """
    print("\n" + "="*60)
    print("ğŸ” STEP 3: Query Engine Search & Answer Generation")
    print("="*60)
    
    # QueryEngineä½œæˆï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•è¨­å®šï¼‰
    print("ğŸ—ï¸  Creating QueryEngine from environment variables...")
    query_engine = QueryEngine()
    
    print(f"   âœ… QueryEngine initialized with:")
    print(f"      â€¢ Retrievers: {[type(r).__name__ for r in query_engine.retrievers]}")
    print(f"      â€¢ Reranker: {type(query_engine.reranker).__name__ if query_engine.reranker else 'None'}")
    print(f"      â€¢ Synthesizer: {type(query_engine.synthesizer).__name__ if query_engine.synthesizer else 'None'}")
    
    # ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªã§æ¤œç´¢ãƒ†ã‚¹ãƒˆï¼ˆæ—¥æœ¬èªãƒ“ã‚¸ãƒã‚¹é–¢é€£ï¼‰
    sample_queries = [
        "ä¼šç¤¾ã®ä¸»ãªäº‹æ¥­å†…å®¹ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã®è£½å“ãƒ©ã‚¤ãƒ³ãƒŠãƒƒãƒ—ã‚’æ•™ãˆã¦ãã ã•ã„",
        "2023å¹´åº¦ã®å£²ä¸Šé«˜ã¨å–¶æ¥­åˆ©ç›Šã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
        "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã®åˆ¶åº¦ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
        "æƒ…å ±ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®å–ã‚Šçµ„ã¿ã¯ã©ã®ã‚ˆã†ãªã‚‚ã®ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ"
    ]
    
    print(f"\nğŸ” Testing {len(sample_queries)} sample queries...")
    
    for i, query_text in enumerate(sample_queries, 1):
        print(f"\nğŸ“ Query {i}: {query_text}")
        print("-" * 50)
        
        try:
            # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            result = query_engine.query(query_text, retriever_top_k=3)
            
            if result.sources:
                print(f"   ğŸ“„ Found {len(result.sources)} relevant documents:")
                
                # æ¤œç´¢çµæœè¡¨ç¤º
                for j, source in enumerate(result.sources, 1):
                    print(f"      {j}. Score: {source.score:.3f}")
                    print(f"         Doc ID: {source.document_id}")
                    print(f"         Content: {source.document.content[:100]}...")
                    
                    # Rerankeræƒ…å ±è¡¨ç¤º
                    if "reranked_by" in source.metadata:
                        reranker_type = source.metadata["reranked_by"]
                        original_score = source.metadata.get("original_score", "N/A")
                        llm_score = source.metadata.get("llm_score", "N/A")
                        print(f"         ğŸ¯ Reranked by: {reranker_type}")
                        print(f"         ğŸ“Š Original â†’ LLM: {original_score:.3f} â†’ {llm_score:.3f}")
                    
                    # Use the retriever_type metadata to show actual storage technology
                    retriever_info = source.metadata.get("retriever_type", "Unknown")
                    retrieval_method = source.metadata.get("retrieval_method", "unknown")
                    
                    if retriever_info != "Unknown":
                        if retrieval_method == "vector_similarity":
                            print(f"         ğŸ” Source: {retriever_info} (vector search)")
                        elif retrieval_method == "keyword_search":
                            print(f"         ğŸ” Source: {retriever_info} (keyword search)")
                        else:
                            print(f"         ğŸ” Source: {retriever_info}")
                    else:
                        print(f"         ğŸ” Source: Unknown")
                
                # ç”Ÿæˆã•ã‚ŒãŸå›ç­”è¡¨ç¤º
                if result.answer:
                    print(f"\n   ğŸ¤– Generated Answer:")
                    print(f"      {result.answer[:150]}{'...' if len(result.answer) > 150 else ''}")
                else:
                    print(f"\n   âš ï¸  No answer generated")
                    if not query_engine.synthesizer:
                        print(f"      ğŸ’¡ No synthesizer configured - only search results available")
                
                print(f"   â±ï¸  Processing time: {result.processing_time:.3f}s")
            else:
                print("   âš ï¸  No relevant documents found")
                
        except Exception as e:
            print(f"   âŒ Query failed: {e}")
    
    return query_engine


def step4_quality_evaluation(query_engine, sample_queries):
    """
    ã‚¹ãƒ†ãƒƒãƒ—4: QualityLabã§å“è³ªè©•ä¾¡
    
    QualityLabã‚‚ç’°å¢ƒå¤‰æ•°ã®è¨­å®šã«åŸºã¥ã„ã¦è‡ªå‹•çš„ã«ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã€
    RAGã‚·ã‚¹ãƒ†ãƒ ã®å“è³ªã‚’åŒ…æ‹¬çš„ã«è©•ä¾¡ã—ã¾ã™ã€‚
    """
    print("\n" + "="*60)
    print("ğŸ”¬ STEP 4: Quality Evaluation with QualityLab")
    print("="*60)
    
    # QualityLabè¨­å®šç”¨ã®ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
    print("ğŸ”§ Setting up QualityLab environment variables...")
    os.environ.setdefault("REFINIRE_RAG_TEST_SUITES", "llm")
    os.environ.setdefault("REFINIRE_RAG_EVALUATORS", "standard") 
    os.environ.setdefault("REFINIRE_RAG_CONTRADICTION_DETECTORS", "llm")
    os.environ.setdefault("REFINIRE_RAG_INSIGHT_REPORTERS", "standard")
    os.environ.setdefault("REFINIRE_RAG_QA_PAIRS_PER_DOCUMENT", "2")
    os.environ.setdefault("REFINIRE_RAG_EVALUATION_TIMEOUT", "30")
    os.environ.setdefault("REFINIRE_RAG_INCLUDE_CONTRADICTION_DETECTION", "true")
    
    print("   âœ… QualityLab evaluation environment configured")
    print(f"      â€¢ Test Suite: {os.environ.get('REFINIRE_RAG_TEST_SUITES')}")
    print(f"      â€¢ Evaluator: {os.environ.get('REFINIRE_RAG_EVALUATORS')}")
    print(f"      â€¢ Contradiction Detector: {os.environ.get('REFINIRE_RAG_CONTRADICTION_DETECTORS')}")
    print(f"      â€¢ Insight Reporter: {os.environ.get('REFINIRE_RAG_INSIGHT_REPORTERS')}")
    
    # QualityLabä½œæˆï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•è¨­å®šï¼‰
    print("\nğŸ—ï¸  Creating QualityLab from environment variables...")
    try:
        quality_lab = QualityLab()
        print("   âœ… QualityLab initialized successfully")
        print(f"      â€¢ Test Suite: {type(quality_lab.test_suite).__name__}")
        print(f"      â€¢ Evaluator: {type(quality_lab.evaluator).__name__}")
        print(f"      â€¢ Contradiction Detector: {type(quality_lab.contradiction_detector).__name__}")
        print(f"      â€¢ Insight Reporter: {type(quality_lab.insight_reporter).__name__}")
    except Exception as e:
        print(f"   âš ï¸  QualityLab initialization failed: {e}")
        print("   ğŸ’¡ Continuing without quality evaluation...")
        return None
    
    # ã‚µãƒ³ãƒ—ãƒ«è©•ä¾¡ã®å®Ÿè¡Œ
    print(f"\nğŸ§ª Running evaluation on business knowledge corpus...")
    try:
        # ç°¡å˜ãªè©•ä¾¡å®Ÿè¡Œï¼ˆå®Ÿéš›ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆã¨è©•ä¾¡ï¼‰
        evaluation_result = quality_lab.evaluate_rag_pipeline(
            corpus_name="business_knowledge",
            query_engine=query_engine,
            sample_size=min(3, len(sample_queries)),  # å°ã•ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã§å®Ÿè¡Œ
            custom_queries=sample_queries[:3] if sample_queries else None
        )
        
        print(f"   âœ… Evaluation completed successfully")
        print(f"   ğŸ“Š Overall Score: {evaluation_result.overall_score:.2f}")
        print(f"   â±ï¸  Total evaluation time: {evaluation_result.processing_time:.2f}s")
        
        # è©³ç´°çµæœè¡¨ç¤º
        if hasattr(evaluation_result, 'metrics') and evaluation_result.metrics:
            print(f"\nğŸ“ˆ Detailed Metrics:")
            for metric, value in evaluation_result.metrics.items():
                if isinstance(value, (int, float)):
                    print(f"      â€¢ {metric}: {value:.3f}")
                else:
                    print(f"      â€¢ {metric}: {value}")
        
        # ã‚¤ãƒ³ã‚µã‚¤ãƒˆè¡¨ç¤º
        if hasattr(evaluation_result, 'insights') and evaluation_result.insights:
            print(f"\nğŸ’¡ Key Insights:")
            for i, insight in enumerate(evaluation_result.insights[:3], 1):  # æœ€åˆã®3ã¤ã®ã¿è¡¨ç¤º
                print(f"      {i}. {insight.get('title', 'Insight')}: {insight.get('description', 'No description')}")
        
        return evaluation_result
        
    except Exception as e:
        print(f"   âŒ Evaluation failed: {e}")
        print(f"   ğŸ’¡ This might be due to missing test data or configuration issues")
        return None


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°: 4ã‚¹ãƒ†ãƒƒãƒ—ã§ã®RAGã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ãƒ»è©•ä¾¡
    
    ã“ã®é–¢æ•°ã¯ä»¥ä¸‹ã®4ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’é †æ¬¡å®Ÿè¡Œã—ã¾ã™ï¼š
    1. ç’°å¢ƒå¤‰æ•°è¨­å®š
    2. ã‚³ãƒ¼ãƒ‘ã‚¹ä½œæˆ
    3. ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³æ¤œç´¢
    4. å“è³ªè©•ä¾¡
    """
    print("ğŸš€ Simple Hybrid RAG Example - 4 Clear Steps")
    print("=" * 60)
    print("This example demonstrates a complete RAG workflow in 4 simple steps:")
    print("1. Environment Variable Setup")
    print("2. Corpus Creation with CorpusManager")
    print("3. Query Engine Search & Answer Generation")
    print("4. Quality Evaluation with QualityLab")
    print()
    print("All components are automatically configured from environment variables!")
    
    try:
        # Step 1: ç’°å¢ƒå¤‰æ•°è¨­å®š
        available_plugins = step1_setup_environment()
        
        # Step 2: ã‚³ãƒ¼ãƒ‘ã‚¹ä½œæˆ
        corpus_manager = step2_create_corpus()
        
        # Step 3: ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³æ¤œç´¢
        query_engine = step3_query_engine_search()
        
        # Step 4: å“è³ªè©•ä¾¡
        sample_queries = [
            "ä¼šç¤¾ã®ä¸»ãªäº‹æ¥­å†…å®¹ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã®è£½å“ãƒ©ã‚¤ãƒ³ãƒŠãƒƒãƒ—ã‚’æ•™ãˆã¦ãã ã•ã„",
            "2023å¹´åº¦ã®å£²ä¸Šé«˜ã¨å–¶æ¥­åˆ©ç›Šã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
            "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã®åˆ¶åº¦ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
            "æƒ…å ±ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®å–ã‚Šçµ„ã¿ã¯ã©ã®ã‚ˆã†ãªã‚‚ã®ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ"
        ]
        evaluation_result = step4_quality_evaluation(query_engine, sample_queries)
        
        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        print("\n" + "="*60)
        print("ğŸ‰ SUCCESS: RAG System Ready with Quality Evaluation!")
        print("="*60)
        print("Your RAG system is now fully configured, tested, and ready to use.")
        print()
        print("Key components initialized:")
        print(f"â€¢ CorpusManager: {len(corpus_manager.retrievers)} retrievers")
        print(f"â€¢ QueryEngine: {[type(r).__name__ for r in query_engine.retrievers]}")
        print(f"â€¢ Reranker: {type(query_engine.reranker).__name__ if query_engine.reranker else 'None'}")
        print(f"â€¢ Synthesizer: {type(query_engine.synthesizer).__name__ if query_engine.synthesizer else 'None'}")
        if evaluation_result:
            print(f"â€¢ QualityLab: Evaluation completed with score {evaluation_result.overall_score:.2f}")
        else:
            print(f"â€¢ QualityLab: Evaluation skipped due to configuration issues")
        print()
        print("ğŸ’¡ Next steps:")
        print("- Try your own queries with: query_engine.query('your question here')")
        print("- Run quality evaluations with: quality_lab.evaluate_rag_pipeline()")
        print("- Explore different environment variable configurations")
        print("- Add your own documents to the corpus")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ ERROR: {e}")
        print("Check the error messages above and ensure all dependencies are installed.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)