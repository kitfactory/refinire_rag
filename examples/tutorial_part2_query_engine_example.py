#!/usr/bin/env python3
"""
Part 2: QueryEngine Tutorial Example
QueryEngineãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ä¾‹

This example demonstrates comprehensive query processing using refinire-rag's QueryEngine
with retrieval, reranking, answer synthesis, and performance monitoring.

ã“ã®ä¾‹ã§ã¯ã€refinire-ragã®QueryEngineã‚’ä½¿ç”¨ã—ãŸåŒ…æ‹¬çš„ãªã‚¯ã‚¨ãƒªå‡¦ç†ã‚’ã€
æ¤œç´¢ã€å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€å›ç­”åˆæˆã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã¨ã¨ã‚‚ã«å®Ÿæ¼”ã—ã¾ã™ã€‚
"""

import sys
import tempfile
import time
from pathlib import Path
from typing import List, Dict, Any

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from refinire_rag.application.corpus_manager_new import CorpusManager
from refinire_rag.application.query_engine import QueryEngine, QueryEngineConfig
from refinire_rag.storage.sqlite_store import SQLiteDocumentStore
from refinire_rag.storage.in_memory_vector_store import InMemoryVectorStore
from refinire_rag.retrieval import (
    SimpleRetriever, SimpleRetrieverConfig,
    SimpleReranker, SimpleRerankerConfig,
    SimpleReader, SimpleReaderConfig,
    HybridRetriever
)
from refinire_rag.keywordstore import TfidfKeywordStore
from refinire_rag.models.query import QueryResult


def setup_sample_corpus(temp_dir: Path) -> tuple:
    """
    Set up a sample corpus for QueryEngine demonstration
    QueryEngineãƒ‡ãƒ¢ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    """
    
    print("ğŸ“š Setting up sample corpus for QueryEngine demo...")
    print("ğŸ“š QueryEngineãƒ‡ãƒ¢ç”¨ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
    
    # Create sample documents / ã‚µãƒ³ãƒ—ãƒ«æ–‡æ›¸ã‚’ä½œæˆ
    documents_dir = temp_dir / "knowledge_base"
    documents_dir.mkdir(exist_ok=True)
    
    # AI Fundamentals / AIåŸºç¤
    (documents_dir / "ai_fundamentals.txt").write_text("""
äººå·¥çŸ¥èƒ½ï¼ˆAIï¼‰ã¨ã¯ã€äººé–“ã®çŸ¥çš„æ´»å‹•ã‚’ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§å†ç¾ã™ã‚‹æŠ€è¡“ã§ã™ã€‚
ä¸»ãªç‰¹å¾´ï¼š
- å­¦ç¿’èƒ½åŠ›ï¼ˆLearningï¼‰ï¼šãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çŸ¥è­˜ã‚’ç²å¾—
- æ¨è«–èƒ½åŠ›ï¼ˆReasoningï¼‰ï¼šè«–ç†çš„æ€è€ƒã¨åˆ¤æ–­
- èªè­˜èƒ½åŠ›ï¼ˆPerceptionï¼‰ï¼šè¦–è¦šãƒ»è´è¦šæƒ…å ±ã®ç†è§£
- å‰µé€ èƒ½åŠ›ï¼ˆCreativityï¼‰ï¼šæ–°ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã®ç”Ÿæˆ

AIã®åˆ†é¡ï¼š
1. å¼±ã„AIï¼ˆNarrow AIï¼‰ï¼šç‰¹å®šã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–
2. å¼·ã„AIï¼ˆGeneral AIï¼‰ï¼šäººé–“ãƒ¬ãƒ™ãƒ«ã®æ±ç”¨çŸ¥èƒ½
3. è¶…AIï¼ˆSuper AIï¼‰ï¼šäººé–“ã‚’è¶…ãˆã‚‹çŸ¥èƒ½

ç¾åœ¨å®Ÿç”¨åŒ–ã•ã‚Œã¦ã„ã‚‹ã®ã¯ä¸»ã«å¼±ã„AIã§ã€
éŸ³å£°èªè­˜ã€ç”»åƒèªè­˜ã€è‡ªç„¶è¨€èªå‡¦ç†ãªã©ã®åˆ†é‡ã§æ´»ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
""", encoding='utf-8')
    
    # Machine Learning / æ©Ÿæ¢°å­¦ç¿’
    (documents_dir / "machine_learning.txt").write_text("""
æ©Ÿæ¢°å­¦ç¿’ï¼ˆMLï¼‰ã¯ã€æ˜ç¤ºçš„ã«ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã™ã‚‹ã“ã¨ãªã
ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãŒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ã—äºˆæ¸¬ãƒ»åˆ†é¡ã‚’è¡Œã†æŠ€è¡“ã§ã™ã€‚

ä¸»è¦ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼š

1. æ•™å¸«ã‚ã‚Šå­¦ç¿’ï¼ˆSupervised Learningï¼‰
   - åˆ†é¡ï¼ˆClassificationï¼‰ï¼šã‚«ãƒ†ã‚´ãƒªäºˆæ¸¬
   - å›å¸°ï¼ˆRegressionï¼‰ï¼šæ•°å€¤äºˆæ¸¬
   - ä¾‹ï¼šã‚¹ãƒ‘ãƒ ãƒ¡ãƒ¼ãƒ«æ¤œå‡ºã€æ ªä¾¡äºˆæ¸¬

2. æ•™å¸«ãªã—å­¦ç¿’ï¼ˆUnsupervised Learningï¼‰
   - ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼šãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
   - æ¬¡å…ƒå‰Šæ¸›ï¼šãƒ‡ãƒ¼ã‚¿ã®ç°¡ç´„åŒ–
   - ä¾‹ï¼šé¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ç•°å¸¸æ¤œçŸ¥

3. å¼·åŒ–å­¦ç¿’ï¼ˆReinforcement Learningï¼‰
   - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç’°å¢ƒã¨ã®ç›¸äº’ä½œç”¨ã§å­¦ç¿’
   - ä¾‹ï¼šã‚²ãƒ¼ãƒ AIã€ãƒ­ãƒœãƒƒãƒˆåˆ¶å¾¡

æ©Ÿæ¢°å­¦ç¿’ã®å¿œç”¨åˆ†é‡ã¯é‡‘èã€åŒ»ç™‚ã€è£½é€ æ¥­ã€
ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãªã©å¤šå²ã«ã‚ãŸã‚Šã¾ã™ã€‚
""", encoding='utf-8')
    
    # Deep Learning / æ·±å±¤å­¦ç¿’
    (documents_dir / "deep_learning.txt").write_text("""
æ·±å±¤å­¦ç¿’ï¼ˆDeep Learningï¼‰ã¯ã€å¤šå±¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’
ä½¿ç”¨ã™ã‚‹æ©Ÿæ¢°å­¦ç¿’ã®æ‰‹æ³•ã§ã™ã€‚

ä¸»è¦ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼š

1. ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆMLPï¼‰
   - å…¨çµåˆå±¤ã«ã‚ˆã‚‹åŸºæœ¬çš„ãªæ§‹é€ 
   - ç”¨é€”ï¼šåˆ†é¡ã€å›å¸°å•é¡Œ

2. ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆCNNï¼‰
   - ç”»åƒå‡¦ç†ã«ç‰¹åŒ–ã—ãŸæ§‹é€ 
   - ç”¨é€”ï¼šç”»åƒèªè­˜ã€ç‰©ä½“æ¤œå‡º

3. å†å¸°ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆRNNï¼‰
   - æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã«é©ã—ãŸæ§‹é€ 
   - æ”¹è‰¯ç‰ˆï¼šLSTMã€GRU
   - ç”¨é€”ï¼šè‡ªç„¶è¨€èªå‡¦ç†ã€éŸ³å£°èªè­˜

4. ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ï¼ˆTransformerï¼‰
   - æ³¨æ„æ©Ÿæ§‹ï¼ˆAttentionï¼‰ã‚’æ ¸ã¨ã—ãŸæ§‹é€ 
   - ç”¨é€”ï¼šæ©Ÿæ¢°ç¿»è¨³ã€è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆGPTã€BERTï¼‰

æ·±å±¤å­¦ç¿’ã®ç™ºå±•ã«ã‚ˆã‚Šã€å¾“æ¥å›°é›£ã¨ã•ã‚Œã¦ã„ãŸ
è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚
""", encoding='utf-8')
    
    # Natural Language Processing / è‡ªç„¶è¨€èªå‡¦ç†
    (documents_dir / "nlp.txt").write_text("""
è‡ªç„¶è¨€èªå‡¦ç†ï¼ˆNLPï¼‰ã¯ã€äººé–“ã®è¨€èªã‚’ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§
ç†è§£ãƒ»ç”Ÿæˆãƒ»æ“ä½œã™ã‚‹æŠ€è¡“åˆ†é‡ã§ã™ã€‚

ä¸»è¦ãªã‚¿ã‚¹ã‚¯ï¼š

1. åŸºæœ¬å‡¦ç†
   - ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ï¼ˆTokenizationï¼‰ï¼šæ–‡ç« ã‚’å˜èªã«åˆ†å‰²
   - å“è©ã‚¿ã‚°ä»˜ã‘ï¼ˆPOS Taggingï¼‰ï¼šå˜èªã®å“è©ã‚’è­˜åˆ¥
   - æ§‹æ–‡è§£æï¼ˆParsingï¼‰ï¼šæ–‡æ³•æ§‹é€ ã®åˆ†æ

2. æ„å‘³ç†è§£
   - å›ºæœ‰è¡¨ç¾èªè­˜ï¼ˆNERï¼‰ï¼šäººåã€åœ°åç­‰ã®æŠ½å‡º
   - æ„Ÿæƒ…åˆ†æï¼ˆSentiment Analysisï¼‰ï¼šæ–‡ç« ã®æ„Ÿæƒ…åˆ¤å®š
   - æ„å›³ç†è§£ï¼ˆIntent Recognitionï¼‰ï¼šç™ºè©±ã®æ„å›³æ¨å®š

3. ç”Ÿæˆã‚¿ã‚¹ã‚¯
   - æ©Ÿæ¢°ç¿»è¨³ï¼ˆMachine Translationï¼‰ï¼šè¨€èªé–“å¤‰æ›
   - æ–‡æ›¸è¦ç´„ï¼ˆText Summarizationï¼‰ï¼šè¦ç‚¹æŠ½å‡º
   - è³ªå•å¿œç­”ï¼ˆQuestion Answeringï¼‰ï¼šè³ªå•ã¸ã®å›ç­”ç”Ÿæˆ

4. å¿œç”¨ã‚·ã‚¹ãƒ†ãƒ 
   - ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆï¼šå¯¾è©±å‹ã‚·ã‚¹ãƒ†ãƒ 
   - æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ï¼šæƒ…å ±æ¤œç´¢
   - éŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆï¼šéŸ³å£°å¯¾è©±

è¿‘å¹´ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®ç™ºå±•ã«ã‚ˆã‚Šã€
NLPã®æ€§èƒ½ã¯å¤§å¹…ã«å‘ä¸Šã—ã¦ã„ã¾ã™ã€‚
""", encoding='utf-8')
    
    # Computer Vision / ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³
    (documents_dir / "computer_vision.txt").write_text("""
ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ï¼ˆCVï¼‰ã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãŒ
è¦–è¦šæƒ…å ±ã‚’ç†è§£ãƒ»è§£é‡ˆã™ã‚‹æŠ€è¡“åˆ†é‡ã§ã™ã€‚

ä¸»è¦ãªå‡¦ç†ã‚¿ã‚¹ã‚¯ï¼š

1. ç”»åƒåˆ†é¡ï¼ˆImage Classificationï¼‰
   - ç”»åƒå…¨ä½“ã®ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®š
   - ä¾‹ï¼šå‹•ç‰©ã®ç¨®é¡è­˜åˆ¥ã€è£½å“åˆ†é¡

2. ç‰©ä½“æ¤œå‡ºï¼ˆObject Detectionï¼‰
   - ç”»åƒå†…ã®ç‰©ä½“ä½ç½®ã¨ç¨®é¡ã‚’ç‰¹å®š
   - ä¾‹ï¼šè‡ªå‹•é‹è»¢ã§ã®æ­©è¡Œè€…æ¤œå‡º

3. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
   - ç”»åƒã®å„ãƒ”ã‚¯ã‚»ãƒ«ã«ãƒ©ãƒ™ãƒ«ä»˜ä¸
   - ä¾‹ï¼šåŒ»ç™‚ç”»åƒã§ã®ç—…å¤‰éƒ¨ä½ç‰¹å®š

4. é¡”èªè­˜ï¼ˆFace Recognitionï¼‰
   - å€‹äººã®é¡”ã‚’è­˜åˆ¥ãƒ»èªè¨¼
   - ä¾‹ï¼šã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚·ã‚¹ãƒ†ãƒ ã€å†™çœŸç®¡ç†

5. å‹•ç”»è§£æï¼ˆVideo Analysisï¼‰
   - æ™‚ç³»åˆ—ã§ã®ç‰©ä½“è¿½è·¡ãƒ»è¡Œå‹•èªè­˜
   - ä¾‹ï¼šç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã€ã‚¹ãƒãƒ¼ãƒ„è§£æ

æŠ€è¡“è¦ç´ ï¼š
- ç‰¹å¾´æŠ½å‡ºï¼šã‚¨ãƒƒã‚¸ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ã€å½¢çŠ¶ã®æ¤œå‡º
- ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ï¼šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨ã®ç…§åˆ
- æ©Ÿæ¢°å­¦ç¿’ï¼šæ·±å±¤å­¦ç¿’ã«ã‚ˆã‚‹è‡ªå‹•ç‰¹å¾´å­¦ç¿’

å¿œç”¨åˆ†é‡ï¼šè‡ªå‹•é‹è»¢ã€åŒ»ç™‚è¨ºæ–­ã€è£½é€ æ¥­ã®å“è³ªç®¡ç†ã€
ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆãªã©å¹…åºƒãæ´»ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
""", encoding='utf-8')
    
    # Initialize storage / ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸åˆæœŸåŒ–
    doc_store = SQLiteDocumentStore(":memory:")
    vector_store = InMemoryVectorStore()
    
    # Build corpus using semantic RAG / ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯RAGã§ã‚³ãƒ¼ãƒ‘ã‚¹æ§‹ç¯‰
    corpus_manager = CorpusManager.create_semantic_rag(doc_store, vector_store)
    
    # Process all documents / å…¨æ–‡æ›¸ã‚’å‡¦ç†
    file_paths = [str(f) for f in documents_dir.glob("*.txt")]
    stats = corpus_manager.build_corpus(file_paths)
    
    print(f"âœ… Corpus setup completed / ã‚³ãƒ¼ãƒ‘ã‚¹ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†:")
    print(f"   Files processed / å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats.total_files_processed}")
    print(f"   Documents created / ä½œæˆæ–‡æ›¸æ•°: {stats.total_documents_created}")
    print(f"   Chunks created / ä½œæˆãƒãƒ£ãƒ³ã‚¯æ•°: {stats.total_chunks_created}")
    print(f"   Processing time / å‡¦ç†æ™‚é–“: {stats.total_processing_time:.3f}s")
    
    return doc_store, vector_store


def demonstrate_basic_queries(query_engine: QueryEngine):
    """
    Demonstrate basic query operations
    åŸºæœ¬çš„ãªã‚¯ã‚¨ãƒªæ“ä½œã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    
    print("\n" + "="*60)
    print("ğŸ” BASIC QUERY OPERATIONS DEMONSTRATION")
    print("ğŸ” åŸºæœ¬ã‚¯ã‚¨ãƒªæ“ä½œã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*60)
    
    # Basic queries / åŸºæœ¬ã‚¯ã‚¨ãƒª
    basic_queries = [
        "AIã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "æ©Ÿæ¢°å­¦ç¿’ã®ç¨®é¡ã‚’æ•™ãˆã¦",
        "æ·±å±¤å­¦ç¿’ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã¯ã©ã‚“ãªã‚‚ã®ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
        "è‡ªç„¶è¨€èªå‡¦ç†ã®å¿œç”¨ä¾‹ã¯ï¼Ÿ",
        "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã§ã§ãã‚‹ã“ã¨ã¯ï¼Ÿ"
    ]
    
    for i, query in enumerate(basic_queries, 1):
        print(f"\nğŸ“ Query {i}: {query}")
        print("-" * 50)
        
        try:
            # Execute query / ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            start_time = time.time()
            result = query_engine.answer(query)
            end_time = time.time()
            
            # Display results / çµæœè¡¨ç¤º
            print(f"ğŸ¤– Answer / å›ç­”:")
            print(f"   {result.answer[:200]}...")
            print(f"")
            print(f"ğŸ“Š Metrics / ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
            print(f"   Processing time / å‡¦ç†æ™‚é–“: {end_time - start_time:.3f}s")
            print(f"   Confidence / ä¿¡é ¼åº¦: {result.confidence:.3f}")
            print(f"   Source count / ã‚½ãƒ¼ã‚¹æ•°: {len(result.sources)}")
            
            # Show source information / ã‚½ãƒ¼ã‚¹æƒ…å ±è¡¨ç¤º
            if result.sources:
                print(f"   Top source / ãƒˆãƒƒãƒ—ã‚½ãƒ¼ã‚¹: {result.sources[0].metadata.get('source', 'Unknown')}")
            
        except Exception as e:
            print(f"âŒ Query failed / ã‚¯ã‚¨ãƒªå¤±æ•—: {e}")


def demonstrate_advanced_configurations(doc_store, vector_store):
    """
    Demonstrate advanced QueryEngine configurations
    é«˜åº¦ãªQueryEngineè¨­å®šã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    
    print("\n" + "="*60)
    print("âš™ï¸  ADVANCED CONFIGURATIONS DEMONSTRATION")
    print("âš™ï¸  é«˜åº¦ãªè¨­å®šã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*60)
    
    # Configuration 1: Performance-optimized / è¨­å®š1: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
    print("\nğŸ“Œ Configuration 1: Performance-Optimized")
    print("ğŸ“Œ è¨­å®š1: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–")
    print("-" * 40)
    
    fast_retriever = SimpleRetriever(
        vector_store, 
        config=SimpleRetrieverConfig(
            top_k=5,
            similarity_threshold=0.2,
            embedding_model="text-embedding-3-small"
        )
    )
    
    fast_reranker = SimpleReranker(
        config=SimpleRerankerConfig(
            top_k=3,
            boost_exact_matches=True
        )
    )
    
    fast_reader = SimpleReader(
        config=SimpleReaderConfig(
            llm_model="gpt-4o-mini",
            max_context_length=1000,
            temperature=0.1
        )
    )
    
    fast_engine = QueryEngine(
        document_store=doc_store,
        vector_store=vector_store,
        retriever=fast_retriever,
        reranker=fast_reranker,
        reader=fast_reader,
        config=QueryEngineConfig(
            enable_query_normalization=False,  # Disable for speed
            include_sources=True,
            max_response_time=5.0
        )
    )
    
    # Test performance configuration / ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®šã‚’ãƒ†ã‚¹ãƒˆ
    test_query = "æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ"
    start_time = time.time()
    result = fast_engine.answer(test_query)
    fast_time = time.time() - start_time
    
    print(f"âœ… Fast Configuration Results / é«˜é€Ÿè¨­å®šçµæœ:")
    print(f"   Query time / ã‚¯ã‚¨ãƒªæ™‚é–“: {fast_time:.3f}s")
    print(f"   Answer length / å›ç­”é•·: {len(result.answer)} chars")
    print(f"   Sources used / ä½¿ç”¨ã‚½ãƒ¼ã‚¹: {len(result.sources)}")
    
    # Configuration 2: Accuracy-optimized / è¨­å®š2: ç²¾åº¦æœ€é©åŒ–
    print("\nğŸ“Œ Configuration 2: Accuracy-Optimized")
    print("ğŸ“Œ è¨­å®š2: ç²¾åº¦æœ€é©åŒ–")
    print("-" * 40)
    
    accurate_retriever = SimpleRetriever(
        vector_store,
        config=SimpleRetrieverConfig(
            top_k=15,
            similarity_threshold=0.05,
            embedding_model="text-embedding-3-large"
        )
    )
    
    accurate_reranker = SimpleReranker(
        config=SimpleRerankerConfig(
            top_k=8,
            boost_exact_matches=True,
            length_penalty_factor=0.05
        )
    )
    
    accurate_reader = SimpleReader(
        config=SimpleReaderConfig(
            llm_model="gpt-4",
            max_context_length=2500,
            temperature=0.2,
            generation_instructions="""
            Provide detailed, accurate answers based on the context.
            Include specific examples and technical details where appropriate.
            Structure your response clearly with main points and supporting details.
            """
        )
    )
    
    accurate_engine = QueryEngine(
        document_store=doc_store,
        vector_store=vector_store,
        retriever=accurate_retriever,
        reranker=accurate_reranker,
        reader=accurate_reader,
        config=QueryEngineConfig(
            enable_query_normalization=True,
            include_sources=True,
            include_confidence=True,
            max_response_time=30.0
        )
    )
    
    # Test accuracy configuration / ç²¾åº¦è¨­å®šã‚’ãƒ†ã‚¹ãƒˆ
    start_time = time.time()
    result = accurate_engine.answer(test_query)
    accurate_time = time.time() - start_time
    
    print(f"âœ… Accurate Configuration Results / é«˜ç²¾åº¦è¨­å®šçµæœ:")
    print(f"   Query time / ã‚¯ã‚¨ãƒªæ™‚é–“: {accurate_time:.3f}s")
    print(f"   Answer length / å›ç­”é•·: {len(result.answer)} chars")
    print(f"   Sources used / ä½¿ç”¨ã‚½ãƒ¼ã‚¹: {len(result.sources)}")
    print(f"   Confidence / ä¿¡é ¼åº¦: {result.confidence:.3f}")
    
    # Configuration 3: Hybrid retrieval / è¨­å®š3: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
    print("\nğŸ“Œ Configuration 3: Hybrid Retrieval")
    print("ğŸ“Œ è¨­å®š3: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢")
    print("-" * 40)
    
    # Setup keyword store / ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¹ãƒˆã‚¢è¨­å®š
    keyword_store = TfidfKeywordStore()
    
    # Build keyword index from documents / æ–‡æ›¸ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
    # Note: In real implementation, this would be done during corpus building
    # æ³¨æ„: å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã“ã‚Œã¯ã‚³ãƒ¼ãƒ‘ã‚¹æ§‹ç¯‰æ™‚ã«è¡Œã‚ã‚Œã¾ã™
    
    hybrid_retriever = HybridRetriever(
        vector_store=vector_store,
        keyword_store=keyword_store,
        vector_weight=0.7,
        keyword_weight=0.3
    )
    
    hybrid_engine = QueryEngine(
        document_store=doc_store,
        vector_store=vector_store,
        retriever=hybrid_retriever,
        reranker=fast_reranker,
        reader=fast_reader
    )
    
    # Test hybrid configuration / ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è¨­å®šã‚’ãƒ†ã‚¹ãƒˆ
    start_time = time.time()
    result = hybrid_engine.answer("deep learning neural network")
    hybrid_time = time.time() - start_time
    
    print(f"âœ… Hybrid Configuration Results / ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è¨­å®šçµæœ:")
    print(f"   Query time / ã‚¯ã‚¨ãƒªæ™‚é–“: {hybrid_time:.3f}s")
    print(f"   Vector + Keyword search / ãƒ™ã‚¯ãƒˆãƒ« + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢")
    print(f"   Sources found / ç™ºè¦‹ã‚½ãƒ¼ã‚¹: {len(result.sources)}")
    
    print(f"\nğŸ“Š Configuration Comparison / è¨­å®šæ¯”è¼ƒ:")
    print(f"   Fast config / é«˜é€Ÿè¨­å®š: {fast_time:.3f}s")
    print(f"   Accurate config / é«˜ç²¾åº¦è¨­å®š: {accurate_time:.3f}s")
    print(f"   Hybrid config / ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è¨­å®š: {hybrid_time:.3f}s")


def demonstrate_query_analysis(query_engine: QueryEngine):
    """
    Demonstrate detailed query result analysis
    è©³ç´°ãªã‚¯ã‚¨ãƒªçµæœåˆ†æã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    
    print("\n" + "="*60)
    print("ğŸ”¬ QUERY RESULT ANALYSIS DEMONSTRATION")
    print("ğŸ”¬ ã‚¯ã‚¨ãƒªçµæœåˆ†æã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*60)
    
    analysis_queries = [
        "CNNã¨RNNã®é•ã„ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "è‡ªç„¶è¨€èªå‡¦ç†ã§ã§ãã‚‹ã“ã¨ã‚’æ•™ãˆã¦",
        "AIã®å€«ç†çš„ãªèª²é¡Œã«ã¤ã„ã¦"  # This may have lower confidence
    ]
    
    for i, query in enumerate(analysis_queries, 1):
        print(f"\nğŸ“ Analysis Query {i}: {query}")
        print("-" * 50)
        
        # Execute with detailed timing / è©³ç´°ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§å®Ÿè¡Œ
        start_time = time.time()
        result = query_engine.answer(query)
        total_time = time.time() - start_time
        
        # Detailed analysis / è©³ç´°åˆ†æ
        print(f"ğŸ” Detailed Analysis / è©³ç´°åˆ†æ:")
        print(f"   Total processing time / ç·å‡¦ç†æ™‚é–“: {total_time:.3f}s")
        print(f"   Answer quality / å›ç­”å“è³ª:")
        print(f"     - Length / é•·ã•: {len(result.answer)} characters")
        print(f"     - Word count / å˜èªæ•°: {len(result.answer.split())}")
        print(f"     - Confidence / ä¿¡é ¼åº¦: {result.confidence:.3f}")
        
        # Confidence interpretation / ä¿¡é ¼åº¦è§£é‡ˆ
        if result.confidence > 0.8:
            confidence_level = "High / é«˜"
        elif result.confidence > 0.5:
            confidence_level = "Medium / ä¸­"
        else:
            confidence_level = "Low / ä½"
        
        print(f"     - Confidence level / ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«: {confidence_level}")
        
        # Source analysis / ã‚½ãƒ¼ã‚¹åˆ†æ
        print(f"   Source analysis / ã‚½ãƒ¼ã‚¹åˆ†æ:")
        print(f"     - Source count / ã‚½ãƒ¼ã‚¹æ•°: {len(result.sources)}")
        
        for j, source in enumerate(result.sources[:3]):
            relevance = source.metadata.get('relevance_score', 'N/A')
            source_title = source.metadata.get('title', f'Document {j+1}')
            print(f"     - Source {j+1}: {source_title}")
            print(f"       Relevance / é–¢é€£åº¦: {relevance}")
            print(f"       Length / é•·ã•: {len(source.content)} chars")
        
        # Answer preview / å›ç­”ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        print(f"   Answer preview / å›ç­”ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
        print(f"     {result.answer[:150]}...")
        
        # Quality indicators / å“è³ªæŒ‡æ¨™
        quality_indicators = []
        if result.sources:
            quality_indicators.append("âœ“ Has sources / ã‚½ãƒ¼ã‚¹ã‚ã‚Š")
        if result.confidence > 0.7:
            quality_indicators.append("âœ“ High confidence / é«˜ä¿¡é ¼åº¦")
        if len(result.answer) > 50:
            quality_indicators.append("âœ“ Detailed answer / è©³ç´°å›ç­”")
        
        print(f"   Quality indicators / å“è³ªæŒ‡æ¨™: {', '.join(quality_indicators)}")


def demonstrate_performance_monitoring(query_engine: QueryEngine):
    """
    Demonstrate performance monitoring across multiple queries
    è¤‡æ•°ã‚¯ã‚¨ãƒªã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    
    print("\n" + "="*60)
    print("ğŸ“Š PERFORMANCE MONITORING DEMONSTRATION")
    print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*60)
    
    # Performance test queries / ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    test_queries = [
        "äººå·¥çŸ¥èƒ½ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "æ©Ÿæ¢°å­¦ç¿’ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç¨®é¡ã¯ï¼Ÿ",
        "æ·±å±¤å­¦ç¿’ã®å¿œç”¨åˆ†é‡ã‚’æ•™ãˆã¦",
        "è‡ªç„¶è¨€èªå‡¦ç†ã®æŠ€è¡“è¦ç´ ã¯ï¼Ÿ",
        "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã§ã§ãã‚‹ã“ã¨ã¯ï¼Ÿ",
        "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä»•çµ„ã¿ã¯ï¼Ÿ",
        "å¼·åŒ–å­¦ç¿’ã®ç‰¹å¾´ã¯ï¼Ÿ",
        "AIã®æ­´å²ã«ã¤ã„ã¦æ•™ãˆã¦"
    ]
    
    print(f"ğŸš€ Running performance test with {len(test_queries)} queries...")
    print(f"ğŸš€ {len(test_queries)}ã‚¯ã‚¨ãƒªã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
    
    results = []
    total_start_time = time.time()
    
    for i, query in enumerate(test_queries, 1):
        print(f"\nâ±ï¸  Query {i}/{len(test_queries)}: {query[:30]}...")
        
        # Execute with timing / ã‚¿ã‚¤ãƒŸãƒ³ã‚°æ¸¬å®šã§å®Ÿè¡Œ
        start_time = time.time()
        try:
            result = query_engine.answer(query)
            end_time = time.time()
            
            query_time = end_time - start_time
            
            # Collect metrics / ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
            metrics = {
                'query': query,
                'time': query_time,
                'confidence': result.confidence,
                'source_count': len(result.sources),
                'answer_length': len(result.answer),
                'success': True
            }
            
            print(f"     âœ… Success: {query_time:.3f}s, confidence: {result.confidence:.3f}")
            
        except Exception as e:
            query_time = time.time() - start_time
            metrics = {
                'query': query,
                'time': query_time,
                'confidence': 0.0,
                'source_count': 0,
                'answer_length': 0,
                'success': False,
                'error': str(e)
            }
            
            print(f"     âŒ Failed: {e}")
        
        results.append(metrics)
    
    total_time = time.time() - total_start_time
    
    # Performance analysis / ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    print(f"\nğŸ“ˆ Performance Analysis / ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ:")
    print("="*50)
    
    successful_results = [r for r in results if r['success']]
    failed_count = len(results) - len(successful_results)
    
    if successful_results:
        avg_time = sum(r['time'] for r in successful_results) / len(successful_results)
        avg_confidence = sum(r['confidence'] for r in successful_results) / len(successful_results)
        avg_sources = sum(r['source_count'] for r in successful_results) / len(successful_results)
        avg_answer_length = sum(r['answer_length'] for r in successful_results) / len(successful_results)
        
        min_time = min(r['time'] for r in successful_results)
        max_time = max(r['time'] for r in successful_results)
        
        print(f"ğŸ“Š Overall Statistics / å…¨ä½“çµ±è¨ˆ:")
        print(f"   Total queries / ç·ã‚¯ã‚¨ãƒªæ•°: {len(test_queries)}")
        print(f"   Successful / æˆåŠŸ: {len(successful_results)}")
        print(f"   Failed / å¤±æ•—: {failed_count}")
        print(f"   Success rate / æˆåŠŸç‡: {len(successful_results)/len(test_queries)*100:.1f}%")
        print(f"   Total time / ç·æ™‚é–“: {total_time:.3f}s")
        print(f"   Throughput / ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {len(test_queries)/total_time:.2f} queries/sec")
        
        print(f"\nâ±ï¸  Timing Statistics / ã‚¿ã‚¤ãƒŸãƒ³ã‚°çµ±è¨ˆ:")
        print(f"   Average response time / å¹³å‡å¿œç­”æ™‚é–“: {avg_time:.3f}s")
        print(f"   Fastest query / æœ€é€Ÿã‚¯ã‚¨ãƒª: {min_time:.3f}s")
        print(f"   Slowest query / æœ€é…ã‚¯ã‚¨ãƒª: {max_time:.3f}s")
        
        print(f"\nğŸ¯ Quality Statistics / å“è³ªçµ±è¨ˆ:")
        print(f"   Average confidence / å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.3f}")
        print(f"   Average sources per query / å¹³å‡ã‚½ãƒ¼ã‚¹æ•°: {avg_sources:.1f}")
        print(f"   Average answer length / å¹³å‡å›ç­”é•·: {avg_answer_length:.0f} characters")
        
        # Performance categories / ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚«ãƒ†ã‚´ãƒª
        fast_queries = [r for r in successful_results if r['time'] < avg_time * 0.8]
        slow_queries = [r for r in successful_results if r['time'] > avg_time * 1.2]
        
        print(f"\nğŸš€ Performance Categories / ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚«ãƒ†ã‚´ãƒª:")
        print(f"   Fast queries (< {avg_time * 0.8:.3f}s): {len(fast_queries)}")
        print(f"   Normal queries: {len(successful_results) - len(fast_queries) - len(slow_queries)}")
        print(f"   Slow queries (> {avg_time * 1.2:.3f}s): {len(slow_queries)}")
        
        if slow_queries:
            print(f"   Slowest query: {slow_queries[0]['query'][:50]}... ({max(r['time'] for r in slow_queries):.3f}s)")
    
    # Engine statistics / ã‚¨ãƒ³ã‚¸ãƒ³çµ±è¨ˆ
    try:
        engine_stats = query_engine.get_engine_stats()
        print(f"\nğŸ”§ Engine Statistics / ã‚¨ãƒ³ã‚¸ãƒ³çµ±è¨ˆ:")
        print(f"   Queries processed: {engine_stats.get('queries_processed', 'N/A')}")
        print(f"   Cache hits: {engine_stats.get('cache_hits', 'N/A')}")
        print(f"   Average retrieval time: {engine_stats.get('average_retrieval_time', 'N/A')}")
        
    except Exception as e:
        print(f"   Engine statistics not available: {e}")


def demonstrate_error_handling(query_engine: QueryEngine):
    """
    Demonstrate error handling and recovery
    ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨å¾©æ—§ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    
    print("\n" + "="*60)
    print("ğŸ› ï¸  ERROR HANDLING DEMONSTRATION")
    print("ğŸ› ï¸  ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*60)
    
    # Test cases with potential issues / å•é¡Œã‚’èµ·ã“ã™å¯èƒ½æ€§ã®ã‚ã‚‹ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    error_test_cases = [
        {
            "query": "",  # Empty query
            "description": "Empty query test / ç©ºã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ"
        },
        {
            "query": "x" * 1000,  # Very long query
            "description": "Extremely long query test / æ¥µç«¯ã«é•·ã„ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ"
        },
        {
            "query": "What is quantum supremacy in blockchain AI?",  # Complex/nonsensical query
            "description": "Complex nonsensical query test / è¤‡é›‘ã§æ„å‘³ä¸æ˜ãªã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ"
        },
        {
            "query": "Tell me about flying unicorns",  # Query with no relevant sources
            "description": "No relevant sources test / é–¢é€£ã‚½ãƒ¼ã‚¹ãªã—ãƒ†ã‚¹ãƒˆ"
        }
    ]
    
    for i, test_case in enumerate(error_test_cases, 1):
        print(f"\nğŸ§ª Test Case {i}: {test_case['description']}")
        print(f"Query: '{test_case['query'][:50]}{'...' if len(test_case['query']) > 50 else ''}'")
        print("-" * 40)
        
        try:
            # Attempt query with timeout / ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§ã‚¯ã‚¨ãƒªè©¦è¡Œ
            start_time = time.time()
            result = query_engine.answer(test_case['query'])
            end_time = time.time()
            
            # Analyze result / çµæœåˆ†æ
            print(f"âœ… Query completed / ã‚¯ã‚¨ãƒªå®Œäº†:")
            print(f"   Time: {end_time - start_time:.3f}s")
            print(f"   Confidence: {result.confidence:.3f}")
            print(f"   Sources found: {len(result.sources)}")
            print(f"   Answer length: {len(result.answer)}")
            
            # Check for low-quality results / ä½å“è³ªçµæœã‚’ãƒã‚§ãƒƒã‚¯
            if result.confidence < 0.3:
                print(f"âš ï¸  Warning: Low confidence result / è­¦å‘Š: ä½ä¿¡é ¼åº¦çµæœ")
            
            if len(result.sources) == 0:
                print(f"âš ï¸  Warning: No sources found / è­¦å‘Š: ã‚½ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            if len(result.answer) < 20:
                print(f"âš ï¸  Warning: Very short answer / è­¦å‘Š: éå¸¸ã«çŸ­ã„å›ç­”")
                
        except Exception as e:
            print(f"âŒ Query failed / ã‚¯ã‚¨ãƒªå¤±æ•—: {e}")
            print(f"   Error type: {type(e).__name__}")
            
            # Provide recovery suggestions / å¾©æ—§ææ¡ˆã‚’æä¾›
            print(f"ğŸ’¡ Recovery suggestions / å¾©æ—§ææ¡ˆ:")
            if "timeout" in str(e).lower():
                print(f"   - Try a simpler query / ã‚ˆã‚Šç°¡å˜ãªã‚¯ã‚¨ãƒªã‚’è©¦ã™")
                print(f"   - Increase timeout limit / ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆåˆ¶é™ã‚’å¢—åŠ ")
            elif "empty" in str(e).lower():
                print(f"   - Provide a non-empty query / ç©ºã§ãªã„ã‚¯ã‚¨ãƒªã‚’æä¾›")
            else:
                print(f"   - Check query format / ã‚¯ã‚¨ãƒªå½¢å¼ã‚’ç¢ºèª")
                print(f"   - Verify corpus content / ã‚³ãƒ¼ãƒ‘ã‚¹å†…å®¹ã‚’ç¢ºèª")


def main():
    """
    Main demonstration function
    ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°
    """
    
    print("ğŸš€ Part 2: QueryEngine Tutorial")
    print("ğŸš€ Part 2: QueryEngineãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«")
    print("="*60)
    print("Comprehensive demonstration of query processing with refinire-rag")
    print("refinire-ragã‚’ä½¿ç”¨ã—ãŸã‚¯ã‚¨ãƒªå‡¦ç†ã®åŒ…æ‹¬çš„ãªãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("")
    print("Features demonstrated / ãƒ‡ãƒ¢æ©Ÿèƒ½:")
    print("âœ“ Basic query operations / åŸºæœ¬ã‚¯ã‚¨ãƒªæ“ä½œ")
    print("âœ“ Advanced configurations / é«˜åº¦ãªè¨­å®š")
    print("âœ“ Query result analysis / ã‚¯ã‚¨ãƒªçµæœåˆ†æ")
    print("âœ“ Performance monitoring / ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–")
    print("âœ“ Error handling / ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°")
    
    # Create temporary directory / ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    temp_dir = Path(tempfile.mkdtemp())
    
    try:
        # Setup sample corpus / ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        print(f"\nğŸ“ Setup: Creating sample corpus in {temp_dir}")
        print(f"ğŸ“ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—: {temp_dir} ã«ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½œæˆä¸­")
        doc_store, vector_store = setup_sample_corpus(temp_dir)
        
        # Initialize basic QueryEngine / åŸºæœ¬QueryEngineã‚’åˆæœŸåŒ–
        print(f"\nğŸ” Initializing basic QueryEngine...")
        print(f"ğŸ” åŸºæœ¬QueryEngineã‚’åˆæœŸåŒ–ä¸­...")
        
        query_engine = QueryEngine(
            document_store=doc_store,
            vector_store=vector_store,
            retriever=SimpleRetriever(vector_store),
            reranker=SimpleReranker(),
            reader=SimpleReader(),
            config=QueryEngineConfig(
                enable_query_normalization=True,
                include_sources=True,
                include_confidence=True
            )
        )
        
        print(f"âœ… QueryEngine initialized successfully")
        print(f"âœ… QueryEngineåˆæœŸåŒ–æˆåŠŸ")
        
        # Demonstration sequence / ãƒ‡ãƒ¢ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
        demonstrate_basic_queries(query_engine)
        demonstrate_advanced_configurations(doc_store, vector_store)
        demonstrate_query_analysis(query_engine)
        demonstrate_performance_monitoring(query_engine)
        demonstrate_error_handling(query_engine)
        
        print("\n" + "="*60)
        print("ğŸ‰ TUTORIAL COMPLETE / ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«å®Œäº†")
        print("="*60)
        print("âœ… All QueryEngine demonstrations completed successfully!")
        print("âœ… ã™ã¹ã¦ã®QueryEngineãƒ‡ãƒ¢ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        print("")
        print("ğŸ“š What you learned / å­¦ç¿’å†…å®¹:")
        print("   â€¢ Basic query operations and result analysis")
        print("     åŸºæœ¬ã‚¯ã‚¨ãƒªæ“ä½œã¨çµæœåˆ†æ")
        print("   â€¢ Advanced component configurations")
        print("     é«˜åº¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè¨­å®š")
        print("   â€¢ Performance optimization techniques")
        print("     ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æŠ€è¡“")
        print("   â€¢ Error handling and recovery strategies")
        print("     ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨å¾©æ—§æˆ¦ç•¥")
        print("   â€¢ Query result quality assessment")
        print("     ã‚¯ã‚¨ãƒªçµæœå“è³ªè©•ä¾¡")
        print("")
        print(f"ğŸ“ Generated files available in: {temp_dir}")
        print(f"ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´æ‰€: {temp_dir}")
        print("")
        print("Next step / æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("â†’ Part 3: Evaluation Tutorial (è©•ä¾¡ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«)")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Tutorial failed / ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # Cleanup (comment out to inspect generated files)
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã™ã‚‹å ´åˆã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
        # shutil.rmtree(temp_dir)
        pass


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)