#!/usr/bin/env python3
"""
TestSuiteä½¿ç”¨ä¾‹

RAGã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from refinire_rag.processing.test_suite import TestSuite, TestSuiteConfig, TestCase
from refinire_rag.models.document import Document


def demo_test_case_generation():
    """ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆã®ãƒ‡ãƒ¢"""
    
    print("ğŸ§ª TestSuite - ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆãƒ‡ãƒ¢")
    print("=" * 60)
    
    # TestSuiteè¨­å®š
    config = TestSuiteConfig(
        auto_generate_cases=True,
        max_cases_per_document=4,
        include_negative_cases=True
    )
    
    test_suite = TestSuite(config)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
    documents = [
        Document(
            id="rag_doc",
            content="""
            RAGï¼ˆRetrieval-Augmented Generationï¼‰ã¯ã€æ¤œç´¢æ‹¡å¼µç”ŸæˆæŠ€è¡“ã§ã™ã€‚
            ã“ã®æŠ€è¡“ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨å¤–éƒ¨çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€
            ã‚ˆã‚Šæ­£ç¢ºã§æ ¹æ‹ ã®ã‚ã‚‹å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
            RAGã®ä¸»ãªåˆ©ç‚¹ã¯ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®æ¸›å°‘ã€çŸ¥è­˜ã®æ›´æ–°å®¹æ˜“æ€§ã€
            å°‚é–€ãƒ‰ãƒ¡ã‚¤ãƒ³ã¸ã®é©å¿œæ€§ã§ã™ã€‚
            è©•ä¾¡æ–¹æ³•ã¨ã—ã¦ã¯ã€BLEUã€ROUGEã€BERTScoreãªã©ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
            """,
            metadata={"title": "RAGæ¦‚è¦", "category": "æŠ€è¡“è§£èª¬"}
        ),
        
        Document(
            id="vector_doc",
            content="""
            ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¯ã€æ„å‘³çš„é¡ä¼¼æ€§ã«åŸºã¥ãæ¤œç´¢æŠ€è¡“ã§ã™ã€‚
            æ–‡æ›¸ã‚„ã‚¯ã‚¨ãƒªã‚’é«˜æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã«åŸ‹ã‚è¾¼ã¿ã€
            ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãªã©ã‚’ä½¿ç”¨ã—ã¦é–¢é€£æ€§ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
            å¾“æ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§ã¯ç™ºè¦‹ã§ããªã„
            æ–‡è„ˆçš„ã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
            å®Ÿè£…æ–¹æ³•ã«ã¯Faissã€Chromaã€Weaviateãªã©ãŒã‚ã‚Šã¾ã™ã€‚
            """,
            metadata={"title": "ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢", "category": "æŠ€è¡“è§£èª¬"}
        )
    ]
    
    print("ğŸ“ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ç”Ÿæˆä¸­...")
    
    all_test_cases = []
    
    for doc in documents:
        result_docs = test_suite.process(doc)
        print(f"\nğŸ“„ Document: {doc.id}")
        print(f"   ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ•°: {result_docs[0].metadata['generated_cases_count']}")
        print(f"   ã‚«ãƒ†ã‚´ãƒª: {result_docs[0].metadata['categories']}")
        
        # å®Ÿéš›ã«ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’è¡¨ç¤º
        print("\nç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹:")
        for case in test_suite.test_cases[-result_docs[0].metadata['generated_cases_count']:]:
            print(f"   - ID: {case.id}")
            print(f"     Query: {case.query}")
            print(f"     Category: {case.category}")
            print(f"     Expected Sources: {case.expected_sources}")
            print()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_file = Path(__file__).parent / "generated_test_cases.json"
    test_suite.save_test_cases(str(output_file))
    print(f"ğŸ’¾ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ä¿å­˜: {output_file}")
    
    return test_suite


def demo_test_execution():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã®ãƒ‡ãƒ¢"""
    
    print("\nğŸ”¬ TestSuite - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ‡ãƒ¢")
    print("=" * 60)
    
    # äº‹å‰å®šç¾©ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã§TestSuiteã‚’ä½œæˆ
    config = TestSuiteConfig(
        auto_generate_cases=False,
        evaluation_criteria={
            "answer_relevance": 0.4,
            "source_accuracy": 0.3,
            "response_time": 0.2,
            "confidence": 0.1
        }
    )
    
    test_suite = TestSuite(config)
    
    # æ‰‹å‹•ã§ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’è¿½åŠ 
    test_cases = [
        TestCase(
            id="test_rag_definition",
            query="RAGã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            expected_sources=["rag_doc"],
            category="definition"
        ),
        TestCase(
            id="test_vector_search",
            query="ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ä»•çµ„ã¿ã‚’èª¬æ˜ã—ã¦ãã ã•ã„",
            expected_sources=["vector_doc"],
            category="how_to"
        ),
        TestCase(
            id="test_irrelevant",
            query="ä»Šæ—¥ã®å¤©æ°—ã¯ã©ã†ã§ã™ã‹ï¼Ÿ",
            expected_sources=[],
            category="negative"
        )
    ]
    
    test_suite.test_cases = test_cases
    
    # è©•ä¾¡å¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
    documents = [
        Document(
            id="rag_doc",
            content="RAGã¯æ¤œç´¢æ‹¡å¼µç”ŸæˆæŠ€è¡“ã§ã€LLMã¨å¤–éƒ¨çŸ¥è­˜ã‚’çµ„ã¿åˆã‚ã›ã¾ã™ã€‚",
            metadata={"title": "RAGæ¦‚è¦"}
        ),
        Document(
            id="vector_doc", 
            content="ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¯æ„å‘³çš„é¡ä¼¼æ€§ã§æ–‡æ›¸ã‚’æ¤œç´¢ã™ã‚‹æŠ€è¡“ã§ã™ã€‚",
            metadata={"title": "ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢"}
        )
    ]
    
    print("ğŸ” ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
    
    for doc in documents:
        result_docs = test_suite.process(doc)
        result_doc = result_docs[0]
        
        print(f"\nğŸ“Š Document: {doc.id} ã®è©•ä¾¡çµæœ")
        print(f"   å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°: {result_doc.metadata['tests_run']}")
        print(f"   æˆåŠŸãƒ†ã‚¹ãƒˆæ•°: {result_doc.metadata['tests_passed']}")
        print(f"   æˆåŠŸç‡: {result_doc.metadata['success_rate']:.1%}")
    
    # å…¨ä½“çš„ãªã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    summary = test_suite.get_test_summary()
    print(f"\nğŸ“ˆ å…¨ä½“ã‚µãƒãƒªãƒ¼:")
    print(f"   ç·ãƒ†ã‚¹ãƒˆæ•°: {summary['total_tests']}")
    print(f"   æˆåŠŸæ•°: {summary['passed_tests']}")
    print(f"   å…¨ä½“æˆåŠŸç‡: {summary['success_rate']:.1%}")
    print(f"   å¹³å‡ä¿¡é ¼åº¦: {summary['average_confidence']:.3f}")
    print(f"   å¹³å‡å‡¦ç†æ™‚é–“: {summary['average_processing_time']:.3f}ç§’")
    
    print("\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ:")
    for category, stats in summary['category_stats'].items():
        success_rate = stats['passed'] / stats['total'] if stats['total'] > 0 else 0
        print(f"   {category}: {stats['passed']}/{stats['total']} ({success_rate:.1%})")
    
    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_file = Path(__file__).parent / "test_results.json"
    test_suite.save_test_results(str(output_file))
    print(f"\nğŸ’¾ ãƒ†ã‚¹ãƒˆçµæœã‚’ä¿å­˜: {output_file}")


def demo_comprehensive_evaluation():
    """åŒ…æ‹¬çš„è©•ä¾¡ã®ãƒ‡ãƒ¢"""
    
    print("\nğŸ† TestSuite - åŒ…æ‹¬çš„è©•ä¾¡ãƒ‡ãƒ¢")
    print("=" * 60)
    
    # ç”Ÿæˆã¨å®Ÿè¡Œã®ä¸¡æ–¹ã‚’è¡Œã†è¨­å®š
    config = TestSuiteConfig(
        auto_generate_cases=True,
        max_cases_per_document=2,
        include_negative_cases=True,
        evaluation_criteria={
            "answer_relevance": 0.5,
            "source_accuracy": 0.3,
            "response_time": 0.2
        }
    )
    
    test_suite = TestSuite(config)
    
    # è©•ä¾¡ç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
    evaluation_docs = [
        Document(
            id="comprehensive_doc",
            content="""
            æƒ…å ±æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡ã¯å¤šé¢çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã™ã€‚
            ç²¾åº¦ï¼ˆPrecisionï¼‰ã¨å†ç¾ç‡ï¼ˆRecallï¼‰ã¯åŸºæœ¬çš„ãªæŒ‡æ¨™ã§ã™ã€‚
            F1ã‚¹ã‚³ã‚¢ã¯ã“ã‚Œã‚‰ã®èª¿å’Œå¹³å‡ã¨ã—ã¦è¨ˆç®—ã•ã‚Œã¾ã™ã€‚
            ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆã‚‚é‡è¦ãªè©•ä¾¡æ‰‹æ³•ã®ä¸€ã¤ã§ã™ã€‚
            RAGã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€æ¤œç´¢ç²¾åº¦ã¨ç”Ÿæˆå“è³ªã®ä¸¡æ–¹ã‚’è©•ä¾¡ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
            """,
            metadata={"title": "è©•ä¾¡æ‰‹æ³•", "category": "è©•ä¾¡"}
        )
    ]
    
    print("ğŸ“‹ åŒ…æ‹¬çš„è©•ä¾¡ã‚’å®Ÿè¡Œä¸­...")
    
    for doc in evaluation_docs:
        # 1. ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ
        print(f"\n1ï¸âƒ£ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ: {doc.id}")
        generation_results = test_suite.process(doc)
        gen_result = generation_results[0]
        
        print(f"   ç”Ÿæˆã•ã‚ŒãŸã‚±ãƒ¼ã‚¹æ•°: {gen_result.metadata['generated_cases_count']}")
        
        # 2. ç”Ÿæˆã•ã‚ŒãŸã‚±ãƒ¼ã‚¹ã§è©•ä¾¡å®Ÿè¡Œ
        print(f"\n2ï¸âƒ£ è©•ä¾¡å®Ÿè¡Œ: {doc.id}")
        test_suite.config.auto_generate_cases = False  # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ
        evaluation_results = test_suite.process(doc)
        eval_result = evaluation_results[0]
        
        print(f"   å®Ÿè¡Œã•ã‚ŒãŸãƒ†ã‚¹ãƒˆæ•°: {eval_result.metadata['tests_run']}")
        print(f"   æˆåŠŸç‡: {eval_result.metadata['success_rate']:.1%}")
    
    # æœ€çµ‚ã‚µãƒãƒªãƒ¼
    final_summary = test_suite.get_test_summary()
    print(f"\nğŸ¯ æœ€çµ‚è©•ä¾¡çµæœ:")
    print(f"   ç·åˆæˆåŠŸç‡: {final_summary['success_rate']:.1%}")
    print(f"   ã‚·ã‚¹ãƒ†ãƒ ä¿¡é ¼åº¦: {final_summary['average_confidence']:.3f}")
    
    # è©•ä¾¡å“è³ªã®åˆ¤å®š
    if final_summary['success_rate'] >= 0.8:
        print("   âœ… è©•ä¾¡: å„ªç§€ãªã‚·ã‚¹ãƒ†ãƒ ")
    elif final_summary['success_rate'] >= 0.6:
        print("   ğŸŸ¡ è©•ä¾¡: è‰¯å¥½ãªã‚·ã‚¹ãƒ†ãƒ ")
    else:
        print("   ğŸ”´ è©•ä¾¡: æ”¹å–„ãŒå¿…è¦")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    print("ğŸš€ TestSuite å®Ÿè£…ä¾‹")
    print("RAGã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™")
    
    try:
        # 1. ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆãƒ‡ãƒ¢
        test_suite = demo_test_case_generation()
        
        # 2. ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ‡ãƒ¢
        demo_test_execution()
        
        # 3. åŒ…æ‹¬çš„è©•ä¾¡ãƒ‡ãƒ¢
        demo_comprehensive_evaluation()
        
        print("\nğŸ‰ TestSuite ãƒ‡ãƒ¢ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("\nğŸ“š TestSuiteã®ä¸»ãªæ©Ÿèƒ½:")
        print("   âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã®è‡ªå‹•ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ")
        print("   âœ… æ‰‹å‹•ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®å®Ÿè¡Œ")
        print("   âœ… ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®ç”Ÿæˆ")
        print("   âœ… ã‚«ãƒ†ã‚´ãƒªåˆ¥è©•ä¾¡çµ±è¨ˆ")
        print("   âœ… çµæœã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿")
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)