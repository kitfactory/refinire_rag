#!/usr/bin/env python3
"""
Simple RAG Workflow Test

This is a simplified test that manually builds a corpus and tests the QueryEngine
without the complex pipeline system, to verify core RAG functionality.
"""

import sys
import tempfile
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from refinire_rag.application.query_engine import QueryEngine, QueryEngineConfig
from refinire_rag.storage.sqlite_store import SQLiteDocumentStore
from refinire_rag.storage.in_memory_vector_store import InMemoryVectorStore
from refinire_rag.retrieval import SimpleRetriever, SimpleReranker, SimpleReader
from refinire_rag.retrieval import SimpleRetrieverConfig, SimpleRerankerConfig, SimpleReaderConfig
from refinire_rag.models.document import Document
from refinire_rag.embedding import TFIDFEmbedder
from refinire_rag.storage.vector_store import VectorEntry


def create_sample_documents() -> list:
    """Create sample documents for testing"""
    
    docs = [
        Document(
            id="doc1",
            content="""
RAGï¼ˆRetrieval-Augmented Generationï¼‰ã¯ã€æ¤œç´¢æ‹¡å¼µç”ŸæˆæŠ€è¡“ã®å®Ÿè£…ã§ã™ã€‚
ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€LLMï¼ˆLarge Language Modelï¼‰ã¨å¤–éƒ¨çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’çµ„ã¿åˆã‚ã›ã€
ã‚ˆã‚Šæ­£ç¢ºã§ä¿¡é ¼æ€§ã®é«˜ã„å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

ä¸»è¦ãªåˆ©ç‚¹ï¼š
- ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå¹»è¦šï¼‰ã®æ¸›å°‘
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªçŸ¥è­˜æ›´æ–°
- å°‚é–€ãƒ‰ãƒ¡ã‚¤ãƒ³ã¸ã®é©å¿œ
- å›ç­”ã®æ ¹æ‹ ã¨ãªã‚‹ã‚½ãƒ¼ã‚¹ã®æä¾›

RAGã‚·ã‚¹ãƒ†ãƒ ã¯ä¼æ¥­ã®æ–‡æ›¸æ¤œç´¢ã€ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã€
ç ”ç©¶æ”¯æ´ãªã©ã®ç”¨é€”ã§åºƒãæ´»ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
""",
            metadata={"title": "RAG Overview", "type": "overview"}
        ),
        
        Document(
            id="doc2", 
            content="""
ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆVector Searchï¼‰ã¯ã€RAGã‚·ã‚¹ãƒ†ãƒ ã®ä¸­æ ¸æŠ€è¡“ã§ã™ã€‚
æ–‡æ›¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã«åŸ‹ã‚è¾¼ã¿ã€æ„å‘³çš„é¡ä¼¼æ€§ã«åŸºã¥ã„ã¦æ¤œç´¢ã‚’è¡Œã„ã¾ã™ã€‚

æŠ€è¡“è¦ç´ ï¼š
- æ–‡æ›¸ã®åŸ‹ã‚è¾¼ã¿ï¼ˆDocument Embeddingï¼‰
- ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆVector Databaseï¼‰
- é¡ä¼¼åº¦è¨ˆç®—ï¼ˆé€šå¸¸ã¯ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰
- è¿‘ä¼¼æœ€è¿‘å‚æ¢ç´¢ï¼ˆANN: Approximate Nearest Neighborï¼‰

äººæ°—ã®ã‚ã‚‹ãƒ™ã‚¯ãƒˆãƒ«DBï¼š
- Chroma: ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
- Pinecone: ãƒãƒãƒ¼ã‚¸ãƒ‰ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹
- Faiss: Facebook AIé–‹ç™ºã®é¡ä¼¼æ€§æ¤œç´¢ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- Weaviate: GraphQLã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æŒã¤ãƒ™ã‚¯ãƒˆãƒ«DB
""",
            metadata={"title": "Vector Search", "type": "technical"}
        ),
        
        Document(
            id="doc3",
            content="""
LLMçµ±åˆã¯ã€RAGã‚·ã‚¹ãƒ†ãƒ ã®å›ç­”ç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚ºã§é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¾ã™ã€‚
æ¤œç´¢ã•ã‚ŒãŸæ–‡æ›¸ã‚’æ–‡è„ˆã¨ã—ã¦ä½¿ç”¨ã—ã€è‡ªç„¶ã§æœ‰ç”¨ãªå›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

çµ±åˆã®ãƒã‚¤ãƒ³ãƒˆï¼š
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°: åŠ¹æœçš„ãªæŒ‡ç¤ºæ–‡ã®è¨­è¨ˆ
- æ–‡è„ˆé•·åˆ¶é™: LLMã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã«å¯¾å¿œ
- æ¸©åº¦è¨­å®š: å‰µé€ æ€§ã¨æ­£ç¢ºæ€§ã®ãƒãƒ©ãƒ³ã‚¹
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªå›ç­”ç”Ÿæˆ

ä¸»è¦ãªLLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼š
- OpenAI GPT-4: é«˜å“è³ªãªè¨€èªç†è§£ã¨ç”Ÿæˆ
- Anthropic Claude: é•·æ–‡å¯¾å¿œã¨å®‰å…¨æ€§é‡è¦–
- Google Gemini: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œ
- ãƒ­ãƒ¼ã‚«ãƒ«LLM: ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã¨ã‚³ã‚¹ãƒˆå‰Šæ¸›
""",
            metadata={"title": "LLM Integration", "type": "technical"}
        )
    ]
    
    return docs


def setup_vector_store(documents: list) -> InMemoryVectorStore:
    """Manually setup vector store with embeddings"""
    
    print("ğŸ“š Setting up vector store with embeddings...")
    
    # Create vector store and embedder
    vector_store = InMemoryVectorStore()
    from refinire_rag.embedding import TFIDFEmbeddingConfig
    config = TFIDFEmbeddingConfig(min_df=1, max_df=1.0)  # Adjust for small corpus
    embedder = TFIDFEmbedder(config=config)
    
    # Fit embedder on document corpus
    corpus_texts = [doc.content for doc in documents]
    embedder.fit(corpus_texts)
    print(f"   âœ… Fitted TF-IDF embedder on {len(corpus_texts)} documents")
    
    # Add documents to vector store
    for doc in documents:
        # Generate embedding
        embedding_result = embedder.embed_text(doc.content)
        
        # Create vector entry
        vector_entry = VectorEntry(
            document_id=doc.id,
            content=doc.content[:200] + "..." if len(doc.content) > 200 else doc.content,
            embedding=embedding_result.vector.tolist(),
            metadata=doc.metadata
        )
        
        # Add to vector store
        vector_store.add_vector(vector_entry)
        print(f"   âœ… Added embedding for {doc.id}: {doc.metadata.get('title', 'No title')}")
    
    print(f"ğŸ“Š Vector store setup completed with {len(documents)} documents")
    return vector_store


def setup_document_store(documents: list) -> SQLiteDocumentStore:
    """Setup document store"""
    
    print("ğŸ“„ Setting up document store...")
    
    doc_store = SQLiteDocumentStore(":memory:")
    
    # Add documents to document store
    for doc in documents:
        doc_store.store_document(doc)
        print(f"   âœ… Stored document {doc.id}: {doc.metadata.get('title', 'No title')}")
    
    print(f"ğŸ“Š Document store setup completed with {len(documents)} documents")
    return doc_store


def test_retrieval_components(vector_store: InMemoryVectorStore, documents: list):
    """Test individual retrieval components"""
    
    print("\n" + "="*60)
    print("ğŸ”§ COMPONENT TESTING")
    print("="*60)
    
    # Test Retriever
    print("\nğŸ“Œ Testing Retriever...")
    from refinire_rag.embedding import TFIDFEmbeddingConfig
    config = TFIDFEmbeddingConfig(min_df=1, max_df=1.0)
    embedder = TFIDFEmbedder(config=config)
    
    # Fit embedder with document corpus
    corpus_texts = [doc.content for doc in documents]
    embedder.fit(corpus_texts)
    
    retriever = SimpleRetriever(vector_store, embedder=embedder)
    
    query = "RAGã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ"
    search_results = retriever.retrieve(query, limit=3)
    
    print(f"   Query: {query}")
    print(f"   Results: {len(search_results)}")
    for i, result in enumerate(search_results, 1):
        print(f"     {i}. Doc {result.document_id} (score: {result.score:.3f})")
        print(f"        {result.document.content[:100]}...")
    
    # Test Reranker
    print("\nğŸ“Œ Testing Reranker...")
    reranker = SimpleReranker()
    reranked_results = reranker.rerank(query, search_results)
    
    print(f"   Reranked from {len(search_results)} to {len(reranked_results)} results")
    for i, result in enumerate(reranked_results, 1):
        print(f"     {i}. Doc {result.document_id} (score: {result.score:.3f})")
    
    # Test Reader
    print("\nğŸ“Œ Testing Reader...")
    reader = SimpleReader()
    answer = reader.read(query, reranked_results)
    
    print(f"   Generated answer ({len(answer)} chars):")
    print(f"     {answer}")
    
    return search_results, reranked_results, answer


def test_query_engine(doc_store: SQLiteDocumentStore, vector_store: InMemoryVectorStore):
    """Test complete QueryEngine workflow"""
    
    print("\n" + "="*60)
    print("ğŸ¤– QUERY ENGINE TESTING") 
    print("="*60)
    
    # Create components  
    from refinire_rag.embedding import TFIDFEmbeddingConfig
    config = TFIDFEmbeddingConfig(min_df=1, max_df=1.0)
    embedder = TFIDFEmbedder(config=config)
    
    # Fit embedder - we need to recreate the corpus texts
    # Since we know the documents, recreate them
    documents = create_sample_documents()
    corpus_texts = [doc.content for doc in documents]
    embedder.fit(corpus_texts)
    
    retriever = SimpleRetriever(vector_store, embedder=embedder)
    reranker = SimpleReranker()
    reader = SimpleReader()
    
    # Create QueryEngine
    query_engine = QueryEngine(
        document_store=doc_store,
        vector_store=vector_store,
        retriever=retriever,
        reader=reader,
        reranker=reranker
    )
    
    print(f"âœ… QueryEngine initialized")
    print(f"   Corpus state: {query_engine.corpus_state}")
    
    # Test queries
    queries = [
        "RAGã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ä»•çµ„ã¿ã‚’æ•™ãˆã¦",
        "LLMçµ±åˆã®ãƒã‚¤ãƒ³ãƒˆã¯ï¼Ÿ",
        "ãŠã™ã™ã‚ã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ•™ãˆã¦"
    ]
    
    for i, query in enumerate(queries, 1):
        print(f"\nğŸ“Œ Query {i}: {query}")
        print("-" * 40)
        
        try:
            result = query_engine.answer(query)
            
            print(f"ğŸ¤– å›ç­”:")
            # Split answer into lines for better formatting
            answer_lines = result.answer.split('\n')
            for line in answer_lines:
                if line.strip():
                    print(f"   {line}")
            
            print(f"\nğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:")
            print(f"   - å‡¦ç†æ™‚é–“: {result.metadata.get('processing_time', 0):.3f}s")
            print(f"   - ã‚½ãƒ¼ã‚¹æ•°: {result.metadata.get('source_count', 0)}")
            print(f"   - ä¿¡é ¼åº¦: {result.confidence:.3f}")
            
            if result.sources:
                print(f"   - ã‚½ãƒ¼ã‚¹:")
                for j, source in enumerate(result.sources[:3], 1):
                    source_title = source.metadata.get('title', f'Document {source.document_id}')
                    print(f"     {j}. {source_title} (score: {source.score:.3f})")
            
        except Exception as e:
            print(f"âŒ Query failed: {e}")
            import traceback
            traceback.print_exc()
    
    # Display engine statistics
    print(f"\nğŸ“ˆ Engine Statistics:")
    stats = query_engine.get_engine_stats()
    print(f"   - Total queries: {stats.get('queries_processed', 0)}")
    print(f"   - Average response time: {stats.get('average_response_time', 0):.3f}s")
    print(f"   - Average retrieval count: {stats.get('average_retrieval_count', 0):.1f}")


def main():
    """Main test function"""
    
    print("ğŸš€ Simple RAG Workflow Test")
    print("="*60)
    print("Testing core RAG functionality with manually built corpus")
    
    try:
        # Create sample documents
        print("\nğŸ“ Creating sample documents...")
        documents = create_sample_documents()
        print(f"Created {len(documents)} sample documents")
        
        # Setup stores
        vector_store = setup_vector_store(documents)
        doc_store = setup_document_store(documents)
        
        # Test individual components
        test_retrieval_components(vector_store, documents)
        
        # Test complete QueryEngine
        test_query_engine(doc_store, vector_store)
        
        print("\nğŸ‰ All tests completed successfully!")
        
    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)